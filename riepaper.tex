\documentclass[runningheads,a4paper]{llncs}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

%\usepackage{amsthm}
\usepackage[hidelinks]{hyperref}
\usepackage{amssymb}
\usepackage{amsmath}
\setcounter{tocdepth}{3}
\usepackage{graphicx}

\RequirePackage{tikz}
% beware
\newcommand{\tikzmark}[1]{\tikz[overlay,remember picture] \node (#1) {};}

\usepackage{etoolbox,xstring,xspace}
\makeatletter
\newcommand*{\ie}{i.e.\@\xspace}
\newcommand*{\eg}{e.g.\@\xspace}
\DeclareRobustCommand{\wrt}{%
    \@ifnextchar{.}%
        {wrt}%
        {wrt.\@\xspace}%
}
\DeclareRobustCommand{\etc}{%
    \@ifnextchar{.}%
        {etc}%
        {etc.\@\xspace}%
}
\makeatother
%\newcommand{\qed}{\hfill \ensuremath{\Box}}

\usepackage{stmaryrd} % for the llbracket and rrbracket


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% References
\newcommand*\lref[1]{\Cref{#1} (\nameref{#1})}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Listings
\usepackage{listings}
\usepackage{xcolor}
\lstset{
   literate={\\\-}{}{0\discretionary{-}{}{}},
   %basicstyle=\normalsize\ttfamily,
   basicstyle=\fontsize{7}{9.5}\selectfont\ttfamily,
   numbers=left,                   % where to put the line-numbers
   numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
   stepnumber=1,                   % the step between two line-numbers. If it's 1, each line
   numbersep=5pt,
   escapechar=Â£,
   captionpos=b,
   breaklines=true,
   moredelim=**[is][{\btHL[hlstyle]}]{`}{`}}

\definecolor{darkred}{RGB}{127,0,0}
\lstdefinestyle{bl}
{
    basicstyle=\fontsize{7}{9.5}\selectfont\ttfamily,
    keywordstyle=\color{darkred},
    identifierstyle=, %plain identifiers for make
    morekeywords={procedure,returns,assert,assume,if,else,then,new},
    morecomment=[l]{//},
    literate=
       {\ :=\ }{{\textcolor{darkred}{:=}}}3
       {\ ==\ }{{\textcolor{darkred}{$=$}}}2
       {[}{{\textcolor{darkred}{[}}}1
       {]}{{\textcolor{darkred}{]}}}1
       {\ &&}{{\textcolor{darkred}{$\band$}}}2
       {\ &&\ }{{\textcolor{darkred}{$\band$}}}2
       {!}{{\textcolor{darkred}{!}}}1
}

\lstdefinestyle{Boogie}
{
    basicstyle=\fontsize{7}{9.5}\selectfont\ttfamily,
    keywordstyle=\color{darkred},
    identifierstyle=, %plain identifiers for make
    morekeywords={type,function,procedure,returns,axiom,requires,ensures,assert,var,if,else,then,while,assume,const,unique,modifies,havoc,free},
    morecomment=[l]{//},
    literate=
       {\ :=\ }{{\textcolor{darkred}{:=}}}3
       {\ ::\ }{{\textcolor{darkred}{::}}}3
       {\ :|\ }{{\textcolor{darkred}{:|}}}3
       {?}{{\textcolor{darkred}{?}}}1
       {\ =}{{\textcolor{darkred}{=}}}2
       {\ =\ }{{\textcolor{darkred}{=}}}2
       {\ ==\ }{{\textcolor{darkred}{$=$}}}2
       {<==>}{{\textcolor{darkred}{$\iff$}}}2
       {\ ==>}{{\textcolor{darkred}{$\implies$}}}3
       {\ ==>\ }{{\textcolor{darkred}{$\implies$}}}3
       {forall\ }{{\textcolor{darkred}{$\forall$}}}1
       {exists\ }{{\textcolor{darkred}{$\exists$}}}1
       {||}{{\textcolor{darkred}{$\bor$}}}1
       {\ |\ }{{\textcolor{darkred}{|}}}2
       {\ &&}{{\textcolor{darkred}{$\band$}}}2
       {\ &&\ }{{\textcolor{darkred}{$\band$}}}2
       {!}{{\textcolor{darkred}{!}}}1
       {!!}{{\textcolor{darkred}{!!}}}2
       {\ !=\ }{{\textcolor{darkred}{$\ne$}}}2
       {\ in\ }{{\textcolor{darkred}{$\in$}}}2
    %otherkeywords={==,::,|,?,=,!},
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Listings
\usepackage{bm}

\DeclareMathOperator{\band}{\bm{\;\land\;}}
\DeclareMathOperator{\bor}{\bm{\;\lor\;}}
\DeclareMathOperator{\suchthat}{:}
\newcommand*{\parfun}{\rightharpoonup}
\newcommand*{\qvars}[2]{#1_{#2}}
\newcommand*{\powerset}[1]{\mathcal{P}(#1)}
\newcommand*{\domainFn}{\mathit{dom}}
\newcommand*{\domain}[1]{\mathit{dom}(#1)}
\newcommand*{\range}[1]{\mathit{rng}(#1)}
\newcommand*{\identity}[0]{\mathit{id}}
\newcommand*{\cardinality}[1]{\left|{#1}\right|}
\newcommand*{\defeq}{\stackrel{\text{\tiny def}}{=}}
\newcommand*{\defiff}{\stackrel{\text{\tiny def}}{\iff}}
\newcommand*{\defimplies}{\stackrel{\text{\tiny def}}{\implies}}
\newcommand*{\setcomp}[2]{\left\{#1\,\middle|\,#2\right\}}
\newcommand*{\evalat}{{\downarrow}}
\newcommand*{\nat}{\mathbb{N}}
\newcommand*{\last}[1]{\mathit{lst}(#1)}
\newcommand*{\first}[1]{\mathit{fst}(#1)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Grammar Stuff
\RequirePackage{tabularx}
\newcommand*{\grammarrow}[2]{$#1$ & $:=$ & #2 \\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Sequence command
\makeatletter
\newsavebox\myboxA
\newsavebox\myboxB
\newlength\mylenA

\newcommand*\seq[2][0.85]{%
    \sbox{\myboxA}{$\m@th#2$}%
    \setbox\myboxB\null% Phantom box
    \ht\myboxB=\ht\myboxA%
    \dp\myboxB=\dp\myboxA%
    \wd\myboxB=#1\wd\myboxA% Scale phantom
    \sbox\myboxB{$\m@th\overline{\copy\myboxB}$}%  Overlined phantom
    \setlength\mylenA{\the\wd\myboxA}%   calc width diff
    \addtolength\mylenA{-\the\wd\myboxB}%
    \ifdim\wd\myboxB<\wd\myboxA%
       \rlap{\hskip 0.5\mylenA\usebox\myboxB}{\usebox\myboxA}%
    \else
        \hskip -0.5\mylenA\rlap{\usebox\myboxA}{\hskip 0.5\mylenA\usebox\myboxB}%
    \fi}
\makeatother
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{cleveref}
\Crefname{figure}{Fig.}{Figs.}

\usepackage{biblatex}
\addbibresource{references.bib}
\DeclareFieldFormat{labelnumberwidth}{\mkbibbold{#1.}}

\usepackage{url}
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% MATH
\newcommand*{\AtomicStatement}{\mathit{AtomicStmt}}
\newcommand*{\ConditionalStatement}{\mathit{CondStmt}}
\newcommand*{\Trace}{\mathit{Trace}}
\newcommand*{\Statement}{\mathit{Stmt}}
\newcommand*{\Store}{\mathit{Store}}
\newcommand*{\Map}{\mathit{Heap}}
\newcommand*{\Address}{\mathit{Addr}}
\newcommand*{\PVar}{\mathit{PVar}}
\newcommand*{\StackFrame}{\mathit{StackF}}
\newcommand*{\Stack}{\mathit{Stack}}
\newcommand*{\Roots}{\mathit{Roots}}
\newcommand*{\Val}{\mathit{Val}}
\newcommand*{\Expr}{\mathit{Expr}}
\newcommand*{\ScalarExpr}{\mathit{ScalarExpr}}
\newcommand*{\MapExpr}{\mathit{MapExpr}}
\newcommand*{\BoolExpr}{\mathit{BoolExpr}}
\newcommand*{\news}{\texttt{new}}
\newcommand*{\nullv}{\texttt{null}}
\newcommand*{\alloc}{\texttt{alloc}}
\newcommand*{\havoc}{\texttt{havoc}}
\newcommand*{\havocf}{\texttt{havoc}^f}
\newcommand*{\assume}{\texttt{assume}}
\newcommand*{\assert}{\texttt{assert}}
\newcommand*{\guard}[2]{\cond(#1)\{#2\}}
\newcommand*{\error}{\texttt{error}}
\newcommand*{\truev}{\texttt{true}}
\newcommand*{\falsev}{\texttt{false}}
\newcommand*{\Values}{\mathit{Val}}
\newcommand{\stack}{{\tilde{\stackf}}}
\newcommand*{\false}{\mathit{false}}
\newcommand{\tr}{tr}
\newcommand*{\proc}{\mathcal{B}}
\newcommand*{\param}{\mathcal{V}}
\newcommand*{\Semantics}{\mathit{Sem}}
\newcommand*{\Contract}{\mathit{Con}}
\newcommand*{\contract}{\mathit{con}}
\newcommand*{\threesim}{%
  \mathrel{\vcenter{\offinterlineskip
  \hbox{$\sim$}\vskip-.35ex\hbox{$\sim$}\vskip-.35ex\hbox{$\sim$}}}}
\newcommand*{\sima}[1]{%
  \mathrel{\vcenter{\offinterlineskip
  \hbox{$\scriptscriptstyle\,\mathcal{#1}$}\vskip-.00ex\hbox{$\sim$}\vskip-.35ex\hbox{$\sim$}}}}
\newcommand*\iso{\approx}
\newcommand*\isoi{\sima{K}}
\newcommand*\isoa{\sima{A}}
\newcommand*\isol{\sima{L}}
\newcommand*\isov{\sima{V}}
\newcommand*\isor{\sima{R}}
%\newcommand*{\compatibleName}{\mathit{com}}
%\newcommand*{\compatible}[1]{\compatibleName(#1)}
\newcommand*{\equivmap}{\mathcal{E}}
\newcommand*{\parcomp}{\parallel}
\newcommand*{\muttermname}{\mathit{mt}}
\newcommand*{\mutterm}[3]{{\muttermname}_{#1}(#2,#3)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Semantics
\newcommand*{\metasem}{\mathcal{L}}
%
\newcommand*\Asemantics{\mathcal{A}}
\newcommand*\asemantics{$\Asemantics$ semantics}
\newcommand*\Csemantics{\mathcal{C}}
\newcommand*\csemantics{$\Csemantics$ semantics}
\newcommand*\Ksemantics{\mathcal{K}}
\newcommand*\ksemantics{$\Ksemantics$ semantics}
\newcommand*\Lsemantics{\mathcal{L}}
\newcommand*\lsemantics{$\Lsemantics$ semantics}
\newcommand*\Msemantics{\mathcal{M}}
\newcommand*\msemantics{$\Msemantics$ semantics}
\newcommand*\Rsemantics{\mathcal{R}}
\newcommand*\rsemantics{$\Rsemantics$ semantics}
\newcommand*\Vsemantics{\mathcal{V}}
\newcommand*\vsemantics{$\Vsemantics$ semantics}
%
\newcommand*\semantics{\{\Csemantics,\Vsemantics,\Rsemantics,\Ksemantics,\Asemantics\}}
%
\newcommand*{\callRuleIsomorphic}{\callRuleConcrete{}}
\newcommand*{\bodyRuleIsomorphic}{\bodyRuleRename{}}
\newcommand*{\composeRuleIsomorphic}{\textnormal{COMK}}
%
\newcommand*{\callRuleAbstract}{\textnormal{CALLA}}
\newcommand*{\bodyRuleAbstract}{\bodyRuleRename{}}
\newcommand*{\composeRuleAbstract}{\textnormal{COMA}}
%
\newcommand*{\callRuleConcrete}{\textnormal{CALLV}}
\newcommand*{\bodyRuleConcrete}{\textnormal{BODC}}
\newcommand*{\composeRuleConcrete}{\textnormal{COMV}}%{\textnormal{COMCVR}}
%
\newcommand*{\callRuleRename}{\callRuleConcrete{}}
\newcommand*{\bodyRuleRename}{\textnormal{BODA}}
\newcommand*{\composeRuleRename}{\composeRuleConcrete{}}
%
\newcommand*{\callRuleVerified}{\callRuleConcrete{}}
\newcommand*{\bodyRuleVerified}{\textnormal{BODV}}
\newcommand*{\composeRuleVerified}{\composeRuleConcrete{}}
%
\newcommand*{\bodyRule}{\textnormal{BOD}}
\newcommand*{\blStore}{STORE}
\newcommand*{\blAssign}{ASSIGN}
%\newcommand*{\blAssignb}{ASSIGNB}
\newcommand*{\blNew}{NEW}
\newcommand*{\blAssume}{ASSUME}
\newcommand*{\blAssertt}{ASSERTT}
\newcommand*{\blAssertf}{ASSERTF}
\newcommand*{\blTrans}{TRANS}
\newcommand*{\blTransDiv}{TRANSD}
\newcommand*{\blCondt}{CONDT}
\newcommand*{\blCondf}{CONDF}
%
%\newcommand{\Equivfilter}{\mathcal{U}}
\newcommand{\diff}{\mathit{effect}}
%
\newcommand*{\PName}{\mathit{Pid}}
\newcommand*{\LVar}{\mathit{Lid}}
\newcommand*{\Field}{\mathit{Fid}}
\newcommand*{\Var}{\mathit{Var}}
\newcommand*{\cond}{\mathtt{if}}
\newcommand*{\call}{\mathtt{call}}
\newcommand*{\body}{\mathtt{body}}
%\newcommand*{\fune}{\texttt{e}}
\newcommand*{\fun}{\texttt{p}}
%\newcommand*{\fung}{\texttt{g}}
\newcommand*{\mkframe}{\mathit{mkframe}}
\newcommand*\pop{\mathit{pop}}
\newcommand*{\eval}[2]{\llbracket #1 \rrbracket_{#2}}
%\newcommand*{\renameName}{\mathit{ren}}
%\newcommand*{\rename}[2]{\mathit{ren}_{#1}(#2)}
\newcommand*{\bijection}[1]{\mathit{in}{\left(#1\right)}}
\newcommand*{\wiso}{%
  \mathrel{\vcenter{\offinterlineskip
  \hbox{$\sim$}\vskip-.35ex\hbox{$\sim$}\vskip-.35ex\hbox{$\sim$}}}}

%%%%%%%%%%%%%%% proof
\newcommand*{\isoCompatibleStates}{\mathit{cpts}}
\newcommand*{\myIsoCompatibleStates}{\mathit{pts}}
\newcommand*{\myIsos}{\mathit{misos}}
\newcommand*{\isoR}{\mathcal{I}}
\newcommand*{\mutR}{\mathcal{M}}
\newcommand*{\store}{\sigma}
\newcommand*{\stackf}{\phi}

\newcommand*{\heapof}[1]{{#1}^{\mathtt{heap}}}
\newcommand*{\stackof}[1]{{#1}^{\mathtt{stack}}}
\newcommand*{\popof}[1]{{#1}^{\mathtt{pop}}}
\newcommand*{\topof}[1]{{#1}^{\mathtt{top}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\RequirePackage{tikz}
\usetikzlibrary{arrows, decorations.markings, calc, fit, trees, backgrounds, hobby, positioning, decorations.pathmorphing, decorations.pathreplacing, shapes.misc, shapes.geometric, matrix, spy}

%\newcommand{\tikzmark}[1]{\tikz[overlay,remember picture] \node (#1) {};}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% arrows
\newcommand\singlearrowsinglem[2]{%
\mathrel{%
\begin{tikzpicture}[baseline= {( $ (current bounding box.south) + (0,+0.85ex) $ )}]
  \node[inner sep=.5ex,minimum width=1em,minimum height=0.8em] (a) {$\scriptstyle #1$};
  \node[inner sep=.5ex,minimum width=1em,minimum height=0.8em] (c) at ($(a) + (0,-0.24)$) {$\scriptscriptstyle{#2}$};
  \coordinate (back) at (a.south west);
  \coordinate (front) at (a.south east);
  \path[draw,implies-,decorate,
    decoration={zigzag,amplitude=0.7pt,segment length=1.2mm,pre length=4pt}]
    (front) -- (back);
  \draw[] ($(front)-(0.07,0.07)$) -- (front) -- ($(front)-(0.07,-0.07)$);
\end{tikzpicture}}%
}

\newcommand\singlearrowtransm[1]{%
\mathrel{%
\begin{tikzpicture}[baseline= {( $ (current bounding box.south) + (0,-0.2ex) $ )}]
  \node[inner sep=.5ex,minimum width=1em] (a) {$\scriptstyle #1$};
  \coordinate (back) at (a.south west);
  \coordinate (front) at (a.south east);
  \path[draw,implies-,decorate,
    decoration={zigzag,amplitude=0.7pt,segment length=1.2mm,pre length=4pt}]
    (front) -- (back);
  \draw[] ($(front)-(0.07,0.07)$) -- (front) -- ($(front)-(0.07,-0.07)$);
  \draw[] ($(back)-(0.07,0.07)$) -- (back) -- ($(back)-(0.07,-0.07)$);
\end{tikzpicture}}%
}
%\newcommand\singlearrowsinglei[2]{%
%\mathrel{%
%\begin{tikzpicture}[baseline= {( $ (current bounding box.south) + (0,+0.85ex) $ )}]
%  \node[inner sep=.0ex,minimum width=0em,minimum height=0.8em] (a) {$\scriptstyle #1$};
%  \node[inner sep=.0ex,minimum width=0em,minimum height=0.8em] (c) at ($(a.west) + (0.05,-0.24)$) {$\scriptscriptstyle\mathcal{#2}$};
%  \coordinate (front) at (a.south west);
%  \coordinate (back) at ($(a.south west)-(1em,0)$);
%  \path[draw,implies-,decorate,
%    decoration={zigzag,amplitude=0.7pt,segment length=1.2mm,pre length=4pt}]
%    (front) -- (back);
%  \draw[] ($(front)-(0.07,0.07)$) -- (front) -- ($(front)-(0.07,-0.07)$);
%  \draw [blue] (current bounding box.south west) rectangle (current bounding box.north east);
%\end{tikzpicture}}}

\newcommand\singlearrowsinglei[2]{%
\mathrel{%
\begin{tikzpicture}[baseline=(front.base)]
  \node[inner sep=0cm] (front) at (0,0) {\strut};
  \coordinate (back) at ($(front)-(1em,0)$);
  \node[inner sep=.0ex,minimum width=0em,minimum height=0.0em,anchor=south west,above right=0cm and 0.01cm of front.west] (super)
	 {$\scriptstyle #1$};
  \node[inner sep=.0ex,minimum width=0em,minimum height=0.0em,anchor=north west,below right=0.01cm and 0.00cm of front.west] (sub)
	 {$\scriptscriptstyle{#2}$};
  \path[draw,implies-,decorate,
    decoration={zigzag,amplitude=0.7pt,segment length=1.2mm,pre length=4pt}]
    (front) -- (back); % the squig line
  \draw[] ($(front)-(0.07,0.07)$) -- (front.west) -- ($(front)-(0.07,-0.07)$); % the arrow part
%  \draw [blue] (current bounding box.south west) rectangle (current bounding box.north east);
\end{tikzpicture}}}

\newcommand\singlearrowtransi[1]{%
\mathrel{%
\begin{tikzpicture}[baseline= {( $ (current bounding box.south) + (0,-0.2ex) $ )}]
  \node[inner sep=.0ex,minimum width=0em] (a) {$\scriptstyle #1$};
  \coordinate (front) at (a.south west);
  \coordinate (back) at ($(a.south west)-(1em,0)$);
  \path[draw,implies-,decorate,
    decoration={zigzag,amplitude=0.7pt,segment length=1.2mm,pre length=4pt}]
    (front) -- (back);
  \draw[] ($(back)-(0.07,0.07)$) -- (back) -- ($(back)-(0.07,-0.07)$);
  \draw[] ($(front)-(0.07,0.07)$) -- (front) -- ($(front)-(0.07,-0.07)$);
\end{tikzpicture}}%
}

\newcommand\doublearrowsinglem[1]{%
\mathrel{%
\begin{tikzpicture}[baseline= {( $ (current bounding box.south) + (0,-0.2ex) $ )}]
  \node[inner sep=.5ex,minimum width=1em] (a) {$\scriptstyle #1$};
  \path[draw,implies-,double distance between line centers=1.5pt,decorate,
    decoration={zigzag,amplitude=0.7pt,segment length=1.2mm,pre=lineto,pre length=4pt}]
    (a.south east) -- (a.south west);
\end{tikzpicture}}%
}

\newcommand\doublearrowtransm[1]{%
\mathrel{%
\begin{tikzpicture}[baseline= {( $ (current bounding box.south) + (0,-0.5ex) $ )}]
  \node[inner sep=.5ex,minimum width=1em] (a) {$\scriptstyle #1$};
  \coordinate (back) at (a.south west);
  \path[draw,implies-,double distance between line centers=1.5pt,decorate,
    decoration={zigzag,amplitude=0.7pt,segment length=1.2mm,pre=lineto,
    pre   length=4pt}]
    (a.south east) -- (back);
  \draw[] ($(back)-(0.07,0.07)$) -- (back) -- ($(back)-(0.07,-0.07)$);
\end{tikzpicture}}%
}

\newcommand\doublearrowsinglei[1]{%
\mathrel{%
\begin{tikzpicture}[baseline= {( $ (current bounding box.south) + (0,-0.1ex) $ )}]
  \node[inner sep=.0ex,minimum width=0em] (a) {$\scriptstyle #1$};
  \path[draw,implies-,double distance between line centers=1.5pt,decorate,
    decoration={zigzag,amplitude=0.7pt,segment length=1.2mm,pre=lineto,
    pre   length=4pt}]
    (a.south west) -- ($(a.south west)-(1em,0)$);
\end{tikzpicture}}%
}

\newcommand\doublearrowtransi[1]{%
\mathrel{%
\begin{tikzpicture}[baseline= {( $ (current bounding box.south) + (0,-0.1ex) $ )}]
  \node[inner sep=.0ex,minimum width=0em] (a) {$\scriptstyle #1$};
  \coordinate (back) at ($(a.south west)-(1em,0)$);
  \path[draw,implies-,double distance between line centers=1.5pt,decorate,
    decoration={zigzag,amplitude=0.7pt,segment length=1.2mm,pre=lineto,
    pre   length=4pt}]
    (a.south west) -- (back);
  \draw[] ($(back)-(0.07,0.07)$) -- (back) -- ($(back)-(0.07,-0.07)$);
\end{tikzpicture}}%
}

\newcommand*{\exeAtom}{\hookrightarrow}
\newcommand*{\concexeAtom}{\hookrightarrow_{\!\!_{\mathcal{C}}}}
\newcommand*{\abstractexeAtom}{\hookrightarrow_{\!\!_{\mathcal{A}}}}

\newcommand*{\exeArrow}[1]{\singlearrowsinglem{}{#1}}
\NewDocumentCommand{\exeDisplay}
	{O{}O{}}
	{\singlearrowsinglem{#1}{#2}}
\NewDocumentCommand{\exeInline}
	{O{}O{}}
	{\singlearrowsinglei{#1}{#2}}

\NewDocumentCommand{\exeParam}
	{O{}O{}}
	{\mathchoice
	    {\exeDisplay[#1][#2]}%
	    {\exeInline[#1][#2]}%
	    {\exeInline[#1][#2]}%
	    {\exeInline[#1][#2]}%
	}

\NewDocumentCommand{\exe}
	{O{}}
	{\exeParam[#1][\Csemantics]}

\NewDocumentCommand{\exeAbstract}
	{O{}}
	{\exeParam[#1][\Asemantics]}

\NewDocumentCommand{\exeIsomorphic}
	{O{}}
	{\exeParam[#1][\Ksemantics]}

\NewDocumentCommand{\exeRename}
	{O{}}
	{\exeParam[#1][\Rsemantics]}

\NewDocumentCommand{\exeVerified}
	{O{}}
	{\exeParam[#1][\Vsemantics]}

\NewDocumentCommand{\exeEither}
	{O{}}
	{\exeParam[#1][\Lsemantics]}

\NewDocumentCommand{\exeEitherCo}
	{O{}}
	{\exeParam[#1][\Lsemantics,\mathit{co}]}

\NewDocumentCommand{\exeRenameCo}
	{O{}}
	{\exeParam[#1][\Rsemantics,\mathit{co}]}

\newcommand*{\exeArrowTrans}{\singlearrowtransm{}}
\NewDocumentCommand{\exeTransDisplay}
	{O{}}
	{\singlearrowtransm{#1}}
\NewDocumentCommand{\exeTransInline}
	{O{}}
	{\singlearrowtransi{#1}}
\NewDocumentCommand{\exeTrans}
	{O{}}
	{\mathchoice
	    {\exeTransDisplay[#1]}
	    {\exeTransInline[#1]}
	    {\exeTransInline[#1]}
	    {\exeTransInline[#1]}%
	}

\newcommand*{\exeAbstractArrow}{\doublearrowsingleem{}}
\newcommand*{\exeAbstractTransArrow}{\doublearrowtransem{}}
\NewDocumentCommand{\exeAbstractTransDisplay}
	{O{}}
	{\doublearrowtransm{#1}}
\NewDocumentCommand{\exeAbstractTransInline}
	{O{}}
	{\doublearrowtransi{#1}}
\NewDocumentCommand{\exeAbstractTrans}
	{O{}}
	{\mathchoice
	    {\exeAbstractTransDisplay[#1]}
	    {\exeAbstractTransInline[#1]}
	    {\exeAbstractTransInline[#1]}
	    {\exeAbstractTransInline[#1]}%
	}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% end arrows

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Rewrite Rules %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\RequirePackage{bussproofs}
\def\defaultHypSeparation{\hskip .05in}
\DeclareDocumentCommand \EvaluationRule {o o o o o m m}
{ %
  \IfValueTF{#1}
   {\AxiomC{$#1$}}
   {\AxiomC{}}
  \IfValueTF{#2}
   {\AxiomC{$#2$}}
   {}
  \IfValueTF{#3}
   {\AxiomC{$#3$}}
   {}
  \IfValueTF{#4}
   {\AxiomC{$#4$}}
   {}
  \IfValueTF{#5}
   {\AxiomC{$#5$}}
   {}
  \RightLabel{#6}
   \IfNoValueTF{#1}{\UnaryInfC{#7}}{
      \IfNoValueTF{#2}{\UnaryInfC{#7}}{
         \IfNoValueTF{#3}{\BinaryInfC{#7}}{
            \IfNoValueTF{#4}{\TrinaryInfC{#7}}{
               \IfNoValueTF{#5}{\QuaternaryInfC{#7}}{
                  \QuinaryInfC{#7}
               }
            }
         }
      }
   }%
   \DisplayProof%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Operational Semantics Rules
\newcommand{\RestrictionOne}{R_1}
\newcommand{\RestrictionTwo}{R_2}
\newcommand*\LcomposeAfullyelided{%
	\EvaluationRule
		[\ldots]
		[\ldots]
		[\store_1,s_1 \exeAbstract[\tr_1] \store_2]
		[\store_2,s_2 \exeAbstract[\tr_2] \store_4]
		{\composeRuleAbstract{}}{$(\store_1,s_1) \parcomp (\store_2,s_2) \exeAbstract[\tr_1,\tr_2] (\store_3,\store_4)$}}
\newcommand*\LcomposeAabstract{%
	\EvaluationRule
		[\RestrictionOne(\tr_1,\tr_2)]
		[\RestrictionTwo(\tr_1,\tr_2)]
		[\store_1,s_1 \exeAbstract[\tr_1] \store_2]
		[\store_2,s_2 \exeAbstract[\tr_2] \store_4]
		{\composeRuleAbstract{}}{$(\store_1,s_1) \parcomp (\store_2,s_2) \exeAbstract[\tr_1,\tr_2] (\store_3,\store_4)$}}
\newcommand*\composeRestrictionOne{\myIsos(\tr_1,\tr_2) \subseteq \identity}
\newcommand*\LcomposeAelided{%
	\EvaluationRule
		[\composeRestrictionOne{}]
		[\RestrictionTwo(\tr_1,\tr_2)]
		[\store_1,s_1 \exeAbstract[\tr_1] \store_2]
		[\store_2,s_2 \exeAbstract[\tr_2] \store_4]
		{\composeRuleAbstract{}}{$(\store_1,s_1) \parcomp (\store_2,s_2) \exeAbstract[\tr_1,\tr_2] (\store_3,\store_4)$}}
\newcommand*\LcomposeA{%
	\EvaluationRule
		%[\composeRestrictionOne{}]
		[\isoR(\tr_1,\tr_2)]
		[\mutR(\tr_1,\tr_2)]
		[\store_1,s_1 \exeAbstract[\tr_1] \store_2]
		[\store_2,s_2 \exeAbstract[\tr_2] \store_4]
		{\composeRuleAbstract{}}{$(\store_1,s_1) \parcomp (\store_2,s_2) \exeAbstract[\tr_1,\tr_2] (\store_3,\store_4)$}}%
\newcommand*\LcomposeK{%
	\EvaluationRule
		[\composeRestrictionOne{}]
		[\store_1,s_1 \exeIsomorphic[\tr_1] \store_2]
		[\store_2,s_2 \exeIsomorphic[\tr_2] \store_4]
		{\composeRuleIsomorphic{}}{$(\store_1,s_1) \parcomp (\store_2,s_2) \exeIsomorphic[\tr_1,\tr_2] (\store_3,\store_4)$}}%
\newcommand*\LcomposeCVR{%
	\EvaluationRule
		[\store_1,s_1 \exeEither[\tr_1] \store_2]
		[\store_2,s_2 \exeEither[\tr_2] \store_4]
		[\Lsemantics{} \in \{\Csemantics{},\Vsemantics,\Rsemantics{}\}]
		{\composeRuleVerified{}}{$(\store_1,s_1) \parcomp (\store_2,s_2) \exeEither[\tr_1,\tr_2] (\store_3,\store_4)$}}
\newcommand*\LcomposeV{%
	\EvaluationRule
		[\store_1,s_1 \exeVerified[\tr_1] \store_2]
		[\store_2,s_2 \exeVerified[\tr_2] \store_4]
		{\composeRuleVerified}{$(\store_1,s_1) \parcomp (\store_2,s_2) \exeVerified[\tr_1,\tr_2] (\store_3,\store_4)$}}
\newcommand*\Lbody{%
	\EvaluationRule
		[(\store_1,\store_3) \in \Contract(\fun)]
		[\store_1,\proc(\fun)\exeEither[\tr] \store_3]
		{\bodyRule{}}{$\store_1,\body~\fun \exeEither[\tr\cdot(\mathtt{ret},\store_3,\popof{\store_3})] \popof{\store_3}$}}
%\newcommand*\LbodyV{%
%	\EvaluationRule
%		[(\store_1,\_) \in \Contract(\fun)]
%		[\store_1,\proc(\fun)\exeVerified[\tr] \store_3]
%		{\bodyRuleVerified{}}{$\store_1,\body~\fun \exeVerified[\tr] \store_3$}}
%\newcommand*\LbodyA{%
%	\EvaluationRule
%		[(\store_1,\_) \in \Contract(\fun)]
%		[\store_1,\proc(\fun)\exeAbstract[\tr] \store_3]
%		{\bodyRuleAbstract{}}{$\store_1,\body~\fun \exeAbstract[\tr] \store_3$}}
\newcommand*\LcallV{%
	\EvaluationRule
		[\mkframe(\store_1,x_1 \ldots x_n),\body~\fun\exeVerified[\tr]\store_3]
		{\callRuleVerified{}}{$(\store_1,\call~\fun(x_1 \ldots x_n) \exeVerified[(\call~\fun(x_1 \ldots x_n),\store_1,\store_3)]\store_3$}}
\newcommand*\LcallA{%
	\EvaluationRule
		[\begin{gathered}
			\domain{h_2} \supseteq \domain{h_1} \\
			((\mkframe(\store_1,x_1 \ldots x_n),h_1)(\stack_1\cdot\stackf,h_2)) \in \Contract(\fun)
		\end{gathered}]
		{\callRuleAbstract{}}{$(\stack_1,h_1),\call~\fun(x_1 \ldots x_n) \exeAbstract[(\call~\fun(x_1 \ldots x_n),(\stack_1,h_1),(\stack_1,h_2))](\stack_1,h_2)$}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\ncui}{closure under isomorphism}
\newcommand{\acui}{closed under isomorphism}
\newcommand{\Ncui}{Closure under isomorphism}
\newcommand{\Acui}{Closed under isomorphism}
\newcommand{\nndui}{non-determinism up-to isomorphism}
\newcommand{\andui}{non-deterministic up-to isomorphism}
\newcommand{\Nndui}{Non-determinism up-to isomorphism}
\newcommand{\Andui}{Non-deterministic up-to isomorphism}
\newcommand{\nwe}{weak \neuti{}}
\newcommand{\awe}{weakly \aeuti{}}
\newcommand{\Nwe}{Weak \neuti{}}
\newcommand{\Awe}{Weakly \aeuti{}}
\newcommand{\nap}{assertion preservation}
\newcommand{\aap}{assertion preserving}
\newcommand{\Nap}{Assertion preservation}
\newcommand{\Aap}{Assertion preserving}

\newcommand*{\isoref}{\hyperref[def:global isomorphism]{\ensuremath{\iso}}}


\begin{document}

\mainmatter  % start of an individual contribution

% first the title is needed
\title{Modular Verification of Procedure Equivalence in the Presence of Memory Allocation}

% a short form should be given in case it is too long for the running head
\titlerunning{Verification of Equivalence with Memory Allocation}

% the name(s) of the author(s) follow(s) next
%
% NB: Chinese authors should write their first names(s) in front of
% their surnames. This ensures that the names appear correctly in
% the running heads and the author index.
%
\author{Tim Wood\inst{1} \and Sophia Drossopolou\inst{1} \and Shuvendu K. Lahiri\inst{2} \and Susan Eisenbach\inst{1}}
%
\authorrunning{Verification of Equivalence with Memory Allocation}
% (feature abused for this document to repeat the title also on left hand pages)

% the affiliations are given next; don't give your e-mail address
% unless you accept that it will be published
\institute{Imperial College \\ London, UK \and Microsoft Research \\ Redmond, USA}

%
% NB: a more complex sample for affiliations and the mapping to the
% corresponding authors can be found in the file "llncs.dem"
% (search for the string "\mainmatter" where a contribution starts).
% "llncs.dem" accompanies the document class "llncs.cls".
%

\toctitle{Lecture Notes in Computer Science}
\tocauthor{Authors' Instructions}
\maketitle

\newcommand*\symdiffequivn{e-equivalence}
\newcommand*\Symdiffequivn{E-equivalence}
\newcommand*\symdiffequiva{e-equivalent}
\newcommand*\Symdiffequiva{E-equivalent}
\newcommand*\cone{challenge~1}
\newcommand*\ctwo{challenge~2}
\newcommand*\cthree{challenge~3}
\newcommand*\cfour{challenge~4}
%\newcommand*\cfive{challenge five}
\newcommand*\Cone{Challenge~1}
\newcommand*\Ctwo{Challenge~2}
\newcommand*\Cthree{Challenge~3}
\newcommand*\Cfour{Challenge~4}
%\newcommand*\Cfive{Challenge five}
\newcommand*\metho{RIE}
\newcommand*\tool{APE}
\newcommand*\Tool{APE}

\begin{abstract}
For most high level languages, two procedures are equivalent if they transform a pair of isomorphic stores to isomorphic stores. However, tools for modular checking of such equivalence impose a stronger check where isomorphism is strengthened to equality of stores. This results in the inability to prove many interesting program pairs with recursion and dynamic memory allocation.

In this work, we present RIE, a methodology to modularly establish equivalence of procedures in the presence of memory allocation, cyclic data structures and recursion. Our technique addresses the need for finding witnesses to isomorphism with angelic allocation, supports reasoning about equivalent procedures calls when the stores are only locally isomorphic, and reasoning about changes in the order of procedure calls. We have implemented RIE by encoding it in the Boogie program verifier. We describe the encoding and prove its soundness.

\keywords{Program Equivalence, Program Verification, Version-aware Verification}
\end{abstract}

\section{Introduction}

Program maintenance dominates the program lifecycle. A study of application bugs that took more than one attempt to fix~\cite{Park2012} found that 22\%-33\% of fixes required a supplementary fix, and found a diverse range of errors including incomplete refactorings. A study of refactorings~\cite{Bavota2012} found that across 12,922 refactorings from three software projects, 15\% of refactorings induced a bug. \emph{Automatic program equivalence verification}~\cite{Godlin09,Lahiri2012,Partush2014,Felsing2014} offers the potential to reduce problems by allowing a programmer to automatically (without programmer annotations) verify that the new version is behaviourally equivalent to the old.

The goal of these verification tools is to make the benefits of program equivalence verification available to programmers who are not verification experts. An automatic equivalence verification tool \emph{takes a pair of programs as input and then outputs whether the programs are equivalent or not} (or perhaps times-out). Program equivalence is undecidable in the general case, however, some success has been achieved on programs with substantially similar structure. Since software is frequently modified in small incremental steps, versions tend to be structurally similar.

We know of two tools designed for fully-automatic program equivalence verification of programs with heaps: Symdiff~\cite{Lahiri2012} and RVT~\cite{Godlin09}. Symdiff~\cite{Kawaguchi2010,Lahiri2012,Lahiri2013,Hawblitzel2013} is built on top of the Boogie~\cite{Barnett2005} intermediate verification language which, in turn, uses the Z3~\cite{DeMoura2008} satisfiability modulo theories (SMT) solver to discharge proof obligations. RVT uses a designed-for-purpose verification algorithm, which passes program fragments to the CMBC~\cite{Clarke2003} bounded model checker.

Symdiff relates heaps using equality (of arrays modelling the heaps), which we will call \emph{\symdiffequivn{}}, so programs that differ in the order or amount of dynamic memory allocation or garbage cannot be verified as equivalent by Symdiff. RVT does support differences in allocation, but assumes that all heap data structures are tree-like.\footnote{For details, see \emph{Definition 2} (and the paragraph following) on page 5 of the 2009 paper by \citeauthor{Godlin09}~\cite{Godlin09}.}

\Symdiffequivn{} is too restrictive for programmers, who expect to be able to replace one procedure with another if the two have identical observable behaviour. A more intuitive notion of procedure equivalence for programs with dynamic memory allocation can be constructed using isomorphism between memory locations. Definitions of program equivalence based on a notion of isomorphism have been used in several formal systems~\cite{Benton2007,Pitts2002}. Our definition of equivalence is:
 \begin{quote}% We need to make the defintion highly visible, as recommended by SL
 \emph{Two procedures are {\em equivalent}, if they terminate for the same set of initial stores, and if both procedures run to completion from isomorphic initial stores, they result in isomorphic final stores}. 
 \end{quote}
 Our definition of equivalence matches intuition: it allows for differences in the order or amount of memory allocation and garbage and is not restricted to tree-like structures.
Achieving automatic and modular verification presents several challenges:
\begin{description}
\item[\Cone{}]What kind of input do we need to give to an SMT solver so that it can even do the verification? We need to establish an isomorphism between unbounded heaps of arbitrary shape when this is computationally infeasible in general. Furthermore, a direct axiomatisation of isomorphism involves existentially quantifying the mapping between memory locations that characterises the isomorphism. SMT based verification systems are not very good at producing witnesses to such existentials and so a direct axiomatisation of isomorphism is ineffective.
\end{description}
Sometimes calls to equivalent procedures occur from stores that are not fully isomorphic, rather the stores are isomorphic in the footprint of the called procedures. This leads to the next two challenges:

\begin{description}
\item[\Ctwo{}]How can our tool determine when stores correspond in the footprint of a called procedure?

\item[\Cthree{}]What should we do about equivalent calls from non-isomorphic stores since they do not necessarily result in isomorphic stores?

\item[\Cfour{}]How do we decide which calls may be equivalent when there may be many possible candidates? Equivalent calls may not occur in the same order in each procedure, and moreover the procedure calls which correspond may differ from execution to execution depending on the initial state (\ie program inputs).
\end{description}
%
%\textbf{\Cone{}}. What kind of input do we need to give to an SMT solver so that it can even do the verification? We need to establish an isomorphism between unbounded heaps of arbitrary shape when this is computationally infeasible in general. Furthermore, a direct axiomatisation of isomorphism involves existentially quantifying the mapping between memory locations that characterises the isomorphism. SMT based verification systems are not very good at producing witnesses to such existentials and so a direct axiomatisation of isomorphism is ineffective.
%
%Sometimes calls to equivalent procedures occur from stores that are not fully isomorphic, rather the stores are isomorphic in the footprint of the called procedures. This leads to the next two challenges:
%
%\textbf{\Ctwo{}}. How can our tool determine when stores correspond in the footprint of a called procedure?
%
%\textbf{\Cthree{}}. What should we do about equivalent calls from non-isomorphic stores since they do not necessarily result in isomorphic stores?
%
%\textbf{\Cfour{}}. How do we decide which calls may be equivalent when there may be many possible candidates? Equivalent calls may not occur in the same order in each procedure, and moreover the procedure calls which correspond may differ from execution to execution depending on the initial state (\ie program inputs).

\subsection{Example}\label{sec:example}
\newcommand*{\copylr}{\texttt{lcopy}}
\newcommand*{\copyrl}{\texttt{rcopy}}
\newcommand*{\lang}{\ensuremath{\mathcal{L}}}

Consider the pair of equivalent procedures in \Cref{fig:copy tree} that differ in the order of memory allocation.

\begin{figure}[htbp]%
\centering%
\noindent\begin{minipage}{.45\textwidth}%
\begin{lstlisting}[style=bl,label=lst:copylr,name=copyex]
lcopy(t,r) modifies {r} {
  if(t != null Â£$\band$Â£ r != null) {
      rl := new;Â£\label{lst:orig copylr alloc1}Â£
      rr := new;Â£\label{lst:orig copylr alloc2}Â£
      n := new;Â£\label{lst:orig copylr parent}Â£Â£\label{lst:orig copylr alloc3}Â£

      lcopy(t.l, rl);Â£\label{lst:orig copylr call1}\tikzmark{lcopy1}Â£
      lcopy(t.r, rr);Â£\label{lst:orig copylr call2}\tikzmark{lcopy2}Â£

      n.l := rl.v;
      n.r := rr.v;
      r.v := n;
} }Â£\label{lst:orig copylr final}Â£
\end{lstlisting}%
\end{minipage}%
\begin{minipage}{.45\textwidth}%
\begin{lstlisting}[style=bl,label=lst:copyrl,firstnumber=auto,name=copyex]
rcopy(t,r) modifies {r} {
  if(t != null Â£$\band$Â£ r != null) {
      rl := new;Â£\label{lst:orig copyrl alloc1}Â£
      rr := new;Â£\label{lst:orig copyrl alloc2}Â£

      Â£\tikzmark{rcopy1}Â£rcopy(t.r, rr);Â£\label{lst:orig copyrl call1}Â£
      Â£\tikzmark{rcopy2}Â£rcopy(t.l, rl);Â£\label{lst:orig copyrl call2}Â£

      n := new;Â£\label{lst:orig copyrl parent}Â£
      n.l := rl.v;
      n.r := rr.v;
      r.v := n;
} }Â£\label{lst:orig copyrl final}Â£
\end{lstlisting}%
\end{minipage}%
\caption[Two procedures, \copylr{} and \copyrl{}, that copy a binary tree]{Both procedures copy a binary tree.
%{Two procedures that copy a binary tree. Procedure \copylr{} copies the left nodes first and then the right nodes, and allocates the parent node before copying the children. Procedure \copyrl{} copies the right nodes and then the left nodes, and allocates the parent node after copying the children.
%The postcondition \texttt{modifies \{r\}} asserts that no existing object, other than \texttt{r}, is modified. For this example our tool \tool{} requires this framing assertion. Our approach can take advantage of any contracts that are available.
\label{fig:copy tree}}%
\begin{tikzpicture}[overlay,remember picture]
\draw[black,dashed] (lcopy1) -- (rcopy2);
\draw[black,dashed] (lcopy2) -- (rcopy1);
\end{tikzpicture}%
\end{figure}
\noindent
Both procedures are intended to copy the passed structure  \texttt{t}. The procedures are equivalent on \emph{any} input, whether the input is tree shaped or not. Our methodology \metho{} (\textbf{R}eplace \textbf{I}somorphism with \textbf{E}quality) and tool \tool{} (\textbf{A}utomatic \textbf{P}rogram \textbf{E}quivalence tool) can discover that. The procedures differ in two ways: Firstly, the allocation of the copied node has been moved from before the recursive calls on \cref{lst:orig copylr parent} to after the recursive calls on \cref{lst:orig copyrl parent}. Secondly, the order of the recursive calls on \cref{lst:orig copylr call1,lst:orig copylr call2} has been reversed on \cref{lst:orig copyrl call1,lst:orig copyrl call2}.   The procedures are written in a simple language we call \lang{}, formalised in \Cref{sec:soundness}.

The procedures are equivalent. An intuition as to why is: when \texttt{t} or \texttt{r} are \texttt{null} both procedures leave the heap unchanged. Otherwise, both procedures recursively copy all the nodes to the left, and all the nodes to the right, and return a newly allocated root node via the parameter \texttt{r}. The only pre-existing object modified by the procedures is the one pointed to by \texttt{r}. It is possible that \texttt{r} aliases a node reachable from \texttt{t}, but even so only the \texttt{v} field of \texttt{r} is written to, and only after the nodes have been copied. The objects allocated to \texttt{rl} and \texttt{rr} do not alias anything, so the recursive calls cannot modify the tree, and hence swapping the order of the recursive calls does not affect the result. The postcondition \texttt{modifies \{r\}} asserts that no existing object, other than \texttt{r}, is modified. For this example, our tool \tool{} requires this framing assertion. Our approach can take advantage of any contracts that are available.

The procedures are not \symdiffequiva{} (so would fail to match in Symdiff) when the stores are related with equality. With non-deterministic allocation a procedure is not even equivalent to itself! It is straightforward to resolve with a deterministic allocator, \eg one that starts at 0 and allocates the next address. Under this deterministic approach a procedure is \symdiffequiva{} with itself, but \copylr{} and \copyrl{} are still not \symdiffequiva{} as the allocations on \Cref{lst:orig copylr parent} and \Cref{lst:orig copyrl parent} are allocated different addresses.

The example illustrates the challenges in the following ways. \textbf{\Cone{}}: equivalence requires that the final stores are isomorphic, but the recursive calls are unbounded so a tool has to check isomorphism of a graph of arbitrary shape and unbounded size. \textbf{\Ctwo{}}: the stores are not equivalent prior to the recursive calls. For instance, in \copylr{} three allocations (\Cref{lst:orig copylr alloc1,lst:orig copylr alloc2,lst:orig copylr alloc3}) have occurred before the recursive calls, but in \copyrl{} only two allocations have occurred (\Cref{lst:orig copyrl alloc1,lst:orig copyrl alloc2}). \textbf{\Cthree{}}: the stores after the related calls on \Cref{lst:orig copylr call1} and \Cref{lst:orig copyrl call2} are not generally isomorphic, since the store after \Cref{lst:orig copyrl call2} contains the effects of two recursive calls but the store after \Cref{lst:orig copylr call1} contains the effect of only one recursive call. \textbf{\Cfour{}}: we do not know in advance which recursive call in \copylr{} (\Cref{lst:orig copylr call1,lst:orig copylr call2}) corresponds to which recursive call in \copyrl{} (\Cref{lst:orig copyrl call1,lst:orig copyrl call2}).

\subsection{Contributions}

We propose a sound methodology, \metho{}, for establishing isomorphic procedure equivalence which is effective in an SMT solver. \metho{} enables our tool \tool{} to tackle \textbf{\cone{}} by automatically establishing isomorphism using under-approximation and heap equality! \metho{} works by proving equivalence under the \emph{angelic allocation} assumption; the memory locations are, as far as possible, assumed to be allocated in such a way as to make isomorphic heaps also equal.

We describe a simple language \lang{} for which isomorphism implies equivalence of observable behaviours, and give a formal definition of what it means for \lang{} to be closed under isomorphism.

\metho{} also simplifies challenges two, three and four. \metho{} allows us to use equality in place of isomorphism, so \textbf{\ctwo{}} is addressed by extending the notion of heap equality to support partial heap equality, which we then apply to an overapproximation of the footprint of the procedures. Furthermore \metho{} rescues us from the need to produce a witness (from \textbf{\cone{}}) to the correspondence between procedure behaviour, instead we address \textbf{\cthree{}} by equating the write effects of equivalent procedures (soundly ignoring unobservable behavioural differences). We combine our technique with mutual summaries to address \textbf{\cfour{}}.

In \Cref{sec:impl} we describe how \metho{} can be implemented to verify program equivalence. In \Cref{sec:soundness} we formalise equivalence and isomorphism and outline \metho{}'s soundness proof. In \Cref{sec:discussion} we discuss the effectiveness and limitations of \metho{}. Finally in \Cref{sec:related} we discuss some related work and conclude.

\section{Encoding in a Verifier}\label{sec:impl}


Our tool \tool{}  takes as input an L program  and produces as output `success', `failure', or times out. It does this by translating the input program into Boogie code, which is fed into the Z3 SMT solver. The source code is available at \url{https://github.com/lexicalscope/ape}.

In this section we illustrate \metho{} by showing how \tool{} encodes the example from \Cref{sec:example} and how that encoding helps overcome the challenges detailed in the introduction. In particular, we show how verification under the assumption of ``angelic allocation'' proceeds.
Previous work typically takes the approach of abstracting or overapproximating programs with dynamic allocation~\cite{Tennent2000,Koutavas2006,Benton2007,Tzevelekos2012}, \emph{storeless semantics}~\cite{Bozga2003} go as far as abstracting away the observable store entirely. We make the surprising observation that under-approximating memory allocation is also a useful approach, and our formal system proves it sound. \metho{} establishes procedure equivalence by checking equivalence for only one pair of execution traces for each initial store. Specifically: \begin{quote}\emph{All} pairs of executions from isomorphic initial stores result in \emph{isomorphic} final stores if at least \emph{one} pair of executions from each initial store results in \emph{equal} final stores.\end{quote} In particular, it is not necessary to consider all pairs of isomorphic initial stores. We prove this in \Cref{sec:soundness}.

\metho{} combines our ideas about establishing isomorphism using SMT technology with the prior work on product programs and mutual summaries to produce an automatic program equivalence tool that can verify our example. Standard single program verification tools can be applied to the problem of procedure equivalence using \emph{product programs}~\cite{Barthe2004,Terauchi2005,Godlin09,Lahiri2012,Barthe2016}, which encode the bodies of a pair of procedures into a single procedure such that verifying a safety property of the product procedure is equivalent to verifying a relational property of the procedure pair~\cite{Barthe2016}. Furthermore, a technique called \emph{mutual summaries}~\cite{Hawblitzel2013} can be applied to induce an SMT solver to search for interesting relations between procedure calls.

\begin{figure}[htbp]%
\centering%
\noindent\begin{lstlisting}[style=Boogie,firstnumber=auto,name=copyex]
procedure lcopy_rcopy(..., h:Heap, t,r:Ref) {
// make twelve copies of the initial heap, h
h_a0,h_a1,h_b0,h_b1,h_c0,h_c1,h_d0,h_d1,h_e0,h_e1,h_f0,h_f1
    := h,h,h,h,h,h,h,h,h,h,h,h;

// inline each procedure once with variables renamed with the given suffix
inline lcopy with variable suffix _a0 and heap h_a0 Â£\label{lst:inline a0}\label{lst:inline lcopy 0}Â£
inline rcopy with variable suffix _a1 and heap h_a1
assume rl_a0 = rl_a1 && rr_a0 = rr_a1 && n_a0 = n_a1; Â£\label{lst:assume a}Â£

// and again for correspondence b
inline lcopy with var suffix _b0 and heap h_b0
inline rcopy with var suffix _b1 and heap h_b1Â£\label{lst:inline rcopy 1}Â£
assume rl_b0 = rl_b1 && rr_b0 = n_b1 && n_b0 = rr_b1; Â£\label{lst:assume b}Â£

// and so on for c,d,e,f

assert equal#heaps(...,h_a0,h_a1) Â£\label{lst:disjunction}Â£
    || equal#heaps(...,h_b0,h_b1)
    || ... /* and so on for c,d,e,f */ }
\end{lstlisting}
\caption{A product procedure encoding of equivalence verification under angelic memory allocation for procedures \copylr{} and \copyrl{}.\label{fig:product}}
\end{figure}

\subsection{Angelic Allocation}

\Tool{} checks equivalence for one pair of executions for each initial store. It does so by searching amongst the possible pairs of executions for a pair that result in equal stores (modulo garbage). Of interest, then, are pairs of executions where particular allocation sites (\news{}) in each procedure are allocated the same addresses. In \Cref{fig:copy tree} there are three allocation sites in each procedure.  This gives six possible correspondences between allocation sites (the variables on the left of the equality are from \copylr{}, and the variables on the right are from \copyrl{}):
\[\begin{aligned}
  a)\quad \mathtt{rl} = \mathtt{rl}, \mathtt{rr} = \mathtt{rr}, \mathtt{n} = \mathtt{n} &&\quad
  b)\quad \mathtt{rl} = \mathtt{rl}, \mathtt{rr} = \mathtt{n}, \mathtt{n} = \mathtt{rr} \\
  c)\quad \mathtt{rl} = \mathtt{rr}, \mathtt{rr} = \mathtt{rl}, \mathtt{n} = \mathtt{n} &&\quad
  d)\quad \mathtt{rl} = \mathtt{rr}, \mathtt{rr} = \mathtt{n}, \mathtt{n} = \mathtt{rl} \\
  e)\quad \mathtt{rl} = \mathtt{n}, \mathtt{rr} = \mathtt{rl}, \mathtt{n} = \mathtt{rr} &&\quad
  f)\quad \mathtt{rl} = \mathtt{n}, \mathtt{rr} = \mathtt{rr}, \mathtt{n} = \mathtt{rl}
\end{aligned}\]

We do not know in advance which correspondence will be useful for verification\footnote{It is interesting to note that in this example the variable names suggest which correspondence is important, perhaps indicating that there may be useful heuristics that could improve performance --- such as trying correspondence $(a)$ first.}. In our example, it happens that correspondence $(a)$ is the useful one. Pairs of (terminating) executions from the same initial store that have allocations in this correspondence will result in equal final stores. Hence, no \emph{direct} checks for isomorphism are required. We will detail how procedure calls are handled shortly.

We induce the solver to search for the useful correspondence by constructing a pair of executions for each correspondence and using a disjunction to assert that at least one of them results in equivalent final stores. The Boogie-like pseudo code in \Cref{fig:product} shows how \tool{} encodes \copylr{} and \copyrl{} into a single (Symdiff-style) product procedure. The \texttt{inline} commands (\eg \cref{lst:inline a0}) are not actual Boogie syntax but should be taken to mean that the statements from the body of the relevant procedure are copied into the product procedure at that point. When the procedures are inlined, they are rewritten to work on their own private copy of the heap with fresh variable names. After each inlined pair a different correspondence between allocation sites is assumed (\cref{lst:assume a,lst:assume b}). Finally a disjunction is asserted to challenge the verifier to prove that the final heaps are equal for at least one of the inlined pairs (\cref{lst:disjunction}).

Thus, \metho{} allows us to establish isomorphism using only heap equality!

\subsection{Heap Equality}\label{sec:extensionality}

Here we described how \tool{} establishes heap equality, and discuss why our approach is powerful. Tools can relate programs in an intensional or extensional way~\cite{Benton2004}. Intensionally equal heaps are defined in the same way, whereas extensionally equal heaps have the same observable properties. For example, the heaps\footnote{$h_0[(5,\mathtt{f})\mapsto 7]$ is the heap made by copying $h_0$ and setting field \texttt{f} of object $5$ to $7$.}  $h_1=h_0[(5,\mathtt{f}) \mapsto 7][(5,\mathtt{g}) \mapsto 8]$ and $h_2=h_0[(5,\mathtt{g}) \mapsto 8][(5,\mathtt{f}) \mapsto 7]$ are not intensionally equal, but they are extensionally equal. Extensional relationships provide a powerful means to reason about reordering of store updates.

\begin{figure}[tbp]
\begin{lstlisting}[style=Boogie,firstnumber=auto,name=copyex]
function $Heap#ReachableEqual($h_1, $h_2:Heap, $roots:Roots) : bool {
 $Heap#ReachableEqual'($h_1, $h_2, $roots) &&
 $Heap#ReachableEqual'($h_2, $h_1, $roots) }

function $Heap#ReachableEqual'($h_1, $h_2:Heap, $roots:Roots) : bool {
 (forall $a:Ref :: {...} (forall <alpha> $f:Field alpha ::
  $Reachable($h_1, $roots, $a) ==> $Read($h_1, $a, $f) == $Read($h_2, $a, $f)))}Â£\label{lst:reachable sets}Â£

function $Reachable($h:Heap, $roots:Roots, $a:Ref) : bool {
 (exists $r:Ref :: {...} $Root($roots, $r) && $Reach($h, $r, $a)) }
\end{lstlisting}
\caption{Extensional equality of the reachable heap region. Written in Boogie.}\label{fig:extensionality}
\end{figure}

\Tool{} uses the extensional axiomatisation of heap equality shown in \Cref{fig:extensionality}. The axiomatisation allows procedures to create different garbage by only requiring equality of the reachable heap. The parameter \texttt{\$roots} is a set of references, and it overapproximates the references that are on the stack. The predicate \texttt{\$Reachable} is an axiomatisation of heap reachability (something is unreachable when in a disjoint part of the heap) and is discussed in \Cref{sec:reachability}.

We define equality between heaps using a pair of implications that say that if an object is reachable in either heap, its fields must be equal in both heaps. An alternative, and perhaps more obvious, definition would be that the reachable sets are equal, and that each object in the reachable set has equal fields in both the heaps. The definitions are equivalent --- since heaps that are equal in their reachable parts have the same reachability relation. On several examples the solver was unable to prove that the reachable sets are equal, but it is able to prove our definition.

\subsection{Procedure Call}\label{sec:recursion}

Challenges two, three and four in the introduction relate to the need to reason modularly about the behaviour of nested procedure calls, such as the recursive calls in the example \Cref{fig:copy tree}. In this section we describe how our encoding in \Cref{fig:mutual summary} leverages \metho{} to address these challenges.

\sloppy

\begin{figure}[h!tbp]
\begin{lstlisting}[style=Boogie,firstnumber=auto,name=copyex]
function $abs_lcopy($strat:int, $h_pre:Heap, t:Ref,r:Ref, $h_post:Heap):bool;Â£\label{lst:abstraction function copylr}Â£
function $abs_rcopy($strat:int, $h_pre:Heap, t:Ref,r:Ref, $h_post:Heap):bool;Â£\label{lst:abstraction function copyrl}Â£

procedure lcopy($strat:int, $h_pre:Heap, t:Ref,r:Ref) returns ($h_post:Heap) Â£\label{lst:lcopy Boogie signature}Â£
 free ensures $abs_lcopy($strat, $h_pre, t, r, $h_post); Â£\label{lst:free postcondition lr}Â£
 ...
 free ensures (forall <alpha> $a:Ref,$f:Field alpha :: Â£\label{lst:frame axiom lr}Â£
  $a != $Null && $Allocated($h_pre,$a) && $Read($h_pre,$a,$f)!=$Read($h_post,$a,$f)
   ==> $ReachableFromParams($h_pre, t, r, $a));
procedure rcopy($strat:int, $h_pre:Heap, t:Ref,r:Ref) returns ($h_post:Heap) Â£\label{lst:rcopy Boogie signature}Â£
 free ensures $abs_rcopy($strat, $h_pre, t, r, $h_post); Â£\label{lst:free postcondition rl}Â£
 ...
 free ensures (forall <alpha> $a:Ref,$f:Field alpha :: Â£\label{lst:frame axiom rl}Â£
  $a != $Null && $Allocated($h_pre,$a) && $Read($h_pre,$a,$f)!=$Read($h_post,$a,$f)
   ==> $ReachableFromParams($h_pre, t, r, $a));

axiom (forall $strat:int,$h_pre_0,$h_post_0,$h_pre_1,$h_post_1:Heap,Â£\label{lst:summary axiom start}Â£
        t_0,r_0,t_1,r_1:Ref ::Â£\label{lst:summary axiom}Â£
 {$abs_lcopy($strat,$h_pre_0, t_0, r_0, $h_post_0),Â£\label{lst:trigger start}Â£
  $abs_rcopy($strat,$h_pre_1, t_1, r_1, $h_post_1)}Â£\label{lst:trigger end}Â£
 $abs_lcopy($strat,$h_pre_0, t_0, r_0, $h_post_0) &&
 $abs_rcopy($strat,$h_pre_1, t_1, r_1, $h_post_1)
  && $Heap#EqualFromParams($h_pre_0, t_0, r_0, $h_pre_1, t_1, r_1)  Â£\label{lst:summary axiom antecedent}Â£
   ==> $SameDiff($h_pre_0, $h_post_0, $h_pre_1, $h_post_1));Â£\label{lst:summary axiom consequent}\label{lst:summary axiom end}Â£
function $SameDiff($h_pre_0, $h_post_0, $h_pre_1, $h_post_1:Heap) : bool {Â£\label{lst:samediff}Â£
 (forall <alpha> $a:Ref,$f:Field alpha ::
  ($Read($h_pre_0, $a, $f) != $Read($h_post_0, $a, $f)
   ==> $Read($h_post_0, $a, $f)==$Read($h_post_1, $a, $f)) &&
  ($Read($h_pre_1, $a, $f) != $Read($h_post_1, $a, $f)
   ==> $Read($h_post_0, $a, $f)==$Read($h_post_0, $a, $f))) }
\end{lstlisting}
\caption{Mutual summary of the \texttt{lcopy} and \texttt{rcopy} procedures. Written in Boogie.}\label{fig:mutual summary}
\end{figure}

Equivalent procedure calls do not always occur from isomorphic stores (\textbf{\ctwo{}}). This is overcome by considering only the region of the heap reachable from the procedure parameters when trying to establish equivalence of procedure calls. This corresponds to the predicate \texttt{\$Heap\#EqualFromParams} on \cref{lst:summary axiom antecedent}, detailed in \Cref{sec:mutual}.

Equivalent procedure calls do not necessarily result in isomorphic stores (\textbf{\cthree}). This is overcome through our choice of procedure summary (\cref{lst:summary axiom consequent}) and a frame axiom. The write effects of a pair of equivalent procedure calls are related by the predicate \texttt{\$SameDiff} (\cref{lst:samediff}). The frame axiom appears as a free postcondition\footnote{A free postcondition may be assumed after a call, but is not checked.} of every procedure (\cref{lst:frame axiom lr,lst:frame axiom rl}).  Both are described below.

Equivalent procedure calls are summarised by the predicate \texttt{\$SameDiff} that relates the pre and post stores of both calls. \texttt{\$SameDiff} approximates the actual behaviour of the procedures a surprising way, although equivalent procedures can vary in the amount and shape of garbage, \texttt{\$SameDiff} states that equivalent procedure calls will always have equal effects, we justify this in \Cref{sec:soundness}.

The framing axioms (\cref{lst:frame axiom lr,lst:frame axiom rl}) restrict the write effects of the procedures to the part of the heap that was reachable from the procedure parameters. The axiom follows from the semantics of \lang{}. 
It is not known in advance which procedure calls might be equivalent (\textbf{\cfour{}}). This is overcome by how the summary of the behaviour of equivalent procedures is encoded. Specifically, the encoding of mutual summaries presented by \citeauthor{Hawblitzel2013}~\cite{Hawblitzel2013} is used to induce the SMT solver to search for related pairs of procedure calls. We detailed this encoding below.

\Cref{fig:mutual summary} shows how \tool{} encodes the mutual summary for the procedures \copylr{} and \copyrl{}. The encoding consists of several parts. Encountered calls to the procedures are abstracted by a pair of uninterpreted predicates (\cref{lst:abstraction function copylr,lst:abstraction function copyrl}) which we call \emph{abstraction predicates}. The predicates are uninterpreted so we precisely control their instantiation. They are given as free postconditions of the procedures \copylr{} (\cref{lst:free postcondition lr}) and \copyrl{} (\cref{lst:free postcondition rl}). Encountering calls to these procedures causes the abstraction predicates to be instantiated in the solver's E-graph. We set \emph{triggers} (\cref{lst:trigger start,lst:trigger end}) so that the solver will instantiate the mutual summary axiom's quantifiers (\cref{lst:summary axiom}) for each pair of instantiations of the abstraction predicates. Non-vacuous instantiations of the axiom occur when the solver is able to establish that the heaps reachable from the call parameters are equal, and hence the antecedent is satisfied.

During a Simplify~\cite{Detlefs2005} style SMT solver proof search the quantifiers that appear in an axiom are instantiated with ground terms from the solver's E-graph that match \emph{triggers} associated with the quantifier. In-turn, the axiom is applied to those instantiations to introduce new terms into the E-graph and so on. Thus, \tool{} controls the proof search by a combination of the logical meaning of the axioms and the quantifier triggers.

The synthetic parameter \texttt{\$strat} of \copylr{} (\cref{lst:lcopy Boogie signature}) and \copyrl{} (\cref{lst:rcopy Boogie signature})  is introduced to prevent the proof search from trying to establish equivalence between procedure calls occurring under different allocation correspondences. For example, in \Cref{fig:product}, the inlining of \copylr{} on \cref{lst:inline lcopy 0} and \cref{lst:inline rcopy 1} will contain recursive calls to \copylr{} and \copyrl{} respectively --- but it is not useful to find relations between these calls as they pertain to different allocations correspondences. Specifically, the disjunction on \cref{lst:disjunction} asserts nothing about the relationship between those heaps. The parameter \texttt{\$strat} represents the allocation correspondence in effect for that call, and the mutual summary trigger (\cref{lst:trigger start,lst:trigger end} of \Cref{fig:mutual summary}) restricts instantiation of the quantifiers to calls which occurred under the same allocation correspondence.

We have completed our illustration of how the \metho{} methodology is implemented in a modular program equivalence tool. Discussion about the effectiveness and limitations of our approach is in \Cref{sec:discussion}.

\section{Soundness of \metho{}}\label{sec:soundness}

We now give a model of \metho{} and summarise a proof of its soundness. The semantics of \lang{} come in two flavours: the \vsemantics{} is the ordinary semantics of \lang{}. The \asemantics{} models our Boogie encoding, which includes the various \textbf{a}pproximations detailed in \Cref{sec:impl}. We establish soundness of \metho{} by showing that equivalence under $\Asemantics$ implies equivalence under $\Vsemantics$.

We expect a mapping between procedures names, $\equivmap$, which pairs procedures that are suspected to be equivalent. \metho{} takes the program and $\equivmap$ as input and tries to prove that indeed all pairs in $\equivmap$ are equivalent.

We start with an overview of the semantics of \lang{}, then define isomorphism and procedure equivalence. Then we detail how the various approximations are modelled in the \asemantics{}. Finally we give \metho{}'s soundness theorem\footnote{Full details of the proof can be found in the first author's PhD thesis~\cite{Wood2016}.}.

\subsection{Semantics of \lang{}}

\begin{figure*}[htbp]
\begin{tabularx}{\linewidth}{ l l X }
	\grammarrow{s_a \in \AtomicStatement}{ $x := e$ | $x := \news()$ | $\assume~b$ | $\assert~b$ | $\call~\fun(x,\dots,x)$ | $e.f := e$ }
	\grammarrow{s \in \Statement}{ $s_a$ | $\guard{b}{s_a}$ | $s;s$ }
	\grammarrow{e \in \ScalarExpr}{ $\nullv$ | $x$ | $e.f$ | $b$ }
	\grammarrow{b \in \BoolExpr}{ $x=y$ | $!b$ | $b \band b$ | $\truev$ | $\falsev$ }
\end{tabularx}

\begin{tabularx}{\linewidth}{ l }
Sets $a \in \Address$, $x \in \LVar$, $f \in \Field$, $p \in \PName$, $v \in \Values \defeq \Address \cup \{\truev, \falsev\}$. \\
Set $\Address$ has one reserved element \texttt{null}. \\
\end{tabularx}

\vspace{0.3cm}
\begin{tabularx}{\linewidth}{ l l }
$h \in \Map $ & $\defeq (\Address \times \Field)\parfun\Values$ where $\forall h,f \suchthat h(\nullv,f)=\nullv$. \\
$\stackf \in \StackFrame $ & $ \defeq \LVar\parfun\Values$ \\
$\stack \in \Stack $ & $ \defeq \StackFrame^*$ \\
$\store \in \Store $ & $ \defeq \Stack \times \Map$, where $\store(x)$ means $\stackf(x)$ when $\store=(\stack\cdot\stackf,h)$ \\
$\tr \in \Trace $ & $ \defeq (\Statement\times\Store\times\Store)^*$ \\
$\mkframe(\store,x_1 \ldots x_n) $ & $\defeq (\stackof{\store}\cdot[x_1\mapsto \store(x_1),\ldots,x_n\mapsto\store(x_n)],\heapof{\store})$ \\
$\proc : \PName \rightarrow \Statement$ & looks up procedure bodies from procedure names. \\
\end{tabularx}

\vspace{0.3cm}
$\heapof{\store}\defeq h$ and $\stackof{\store}\defeq \stack\cdot\stackf$ and $\popof{\store} \defeq (\stack,h)$ and $\topof{\store} \defeq \stackf$ when $\store=(\stack\cdot\stackf,h)$


\vspace{0.5cm}
\EvaluationRule
	{\blStore{}}{$\store,e_1.f := e_2 \exeAtom (\stackof{\store},\heapof{\store}[(\eval{e_1}{\store},f)\mapsto\eval{e_2}{\store}]) $}%

\vspace{0.5cm}
\EvaluationRule
	%[a \notin \range{\heapof{\store}}]
	[a \notin \domain{h}]
        [\{f_1,\ldots,f_n\} = \Field]
        [a \ne \nullv]
	{\blNew{}}{$(\stack\cdot\stackf,h),x:=\news() \exeAtom (\stack\cdot\stackf[x\mapsto a],h[(a,f_1)\mapsto \nullv,\ldots,(a,f_n)\mapsto \nullv]))$}

\vspace{0.5cm}
\EvaluationRule
	[\store \vDash b]
	{\blAssertt{}}{$\store,\assert~b \exeAtom \store$}%
\hfill\EvaluationRule
        [\store_1,s \exeAtom \store_2]
	{ATOM}{$\store_1,s \exeEither[s,\store_1,\store_2] \store_2$}%

\vspace{0.5cm}
\EvaluationRule
	[\store \vDash b]
	{\blAssume{}}{$\store,\assume~b \exeAtom \store$}%
\hfill\EvaluationRule
	[\neg(\store \vDash b)]
	{\blAssertf{}}{$\store,\assert~b \exeAtom \error$}

\vspace{0.5cm}
\EvaluationRule
	{\blAssign{}}{$\store,x:=e \exeAtom (\stackof{\store}[x\mapsto\eval{e}{\store}],\heapof{\store})$}%
\hfill\EvaluationRule
	[\store_1 \vDash b]
        [\store_1,s_a \exeEither[\tr] \store_2]
	{\blCondt{}}{$\store_1,\guard{b}{s_a} \exeEither[\tr] \store_2$}%

\vspace{0.5cm}
\EvaluationRule
	[\neg(\store \vDash b)]
	{\blCondf{}}{$\store,\guard{b}{s_a} \exeEither[\guard{b}{s_a},\store,\store] \store$}%
\hfill\EvaluationRule
	[\store_1,s_1 \exeEither[\tr_1] \store_2]
        [\store_2,s_2 \exeEither[\tr_2] \store_3]
	{\blTrans{}}{$\store_1,s_1;s_2 \exeEither[tr_1 \cdot tr_2] \store_3$}

\vspace{0.5cm}
\EvaluationRule
        [\phantom{\store(x)}]
	{}{$\eval{\nullv}{\store}=\nullv$}%
\hfill\EvaluationRule
        [\phantom{\store(x)}]
	{}{$\eval{x}{\store}=\store(x)$}%
\hfill\EvaluationRule
        [\neg(\store \vDash b)]
	{}{$\store \vDash !b$}%
\hfill\EvaluationRule
        [\store \vDash b]
	{}{$\eval{b}{\store}=\truev$}%
\hfill\EvaluationRule
        [\neg(\store \vDash b)]
	{}{$\eval{b}{\store}=\falsev$}%
\vspace{0.5cm}

\EvaluationRule
        [\phantom{\store(x)}]
	{}{$\eval{e.f}{\store}=\heapof{\store}(\eval{e}{\store},f)$}%
\hfill\EvaluationRule
        [\store(x)=\store(y)]
	{}{$\store \vDash x=y$}%
\hfill\EvaluationRule
        [\store(x)=\truev]
	{}{$\store \vDash x$}%
\hfill\EvaluationRule
        [\store \vDash b_1]
        [\store \vDash b_2]
	{}{$\store \vDash b_1 \,\band\, b_2$}
%	{}{$\store \vDash b_1 \,\mathtt{\&\&}\, b_2$}
\caption{Grammar and Operations of \lang{}}\label{fig:bl-op-sem}
\end{figure*}

\begin{figure*}[htbp]
\vspace{0.5cm}
\Lbody{}%

\vspace{0.5cm}
\LcallV{}

\vspace{0.5cm}
\LcallA{}

%\vspace{0.5cm}
%\LbodyV{}%

\vspace{0.5cm}
\LcomposeV{}%

\vspace{0.5cm}
\LcomposeA{}%

\caption{Procedure call and composition rules of \lang{}}\label{fig:bl call and compose}
\end{figure*}

\lang{} is a simple imperative language. \Cref{fig:bl-op-sem} describes the standard aspects of \lang{}, while \Cref{fig:bl call and compose} describes the non-standard aspects. The following points are interesting about our semantics: 
\begin{itemize}
\item  We distinguish between execution under $\Vsemantics$ and $\Asemantics$ with a subscript, writing $\exeEither$ where $\metasem \in \{\Vsemantics,\Asemantics\}$.
\item We split procedure call into two: a ``call'' rule and a ``body'' rule, similar to \citeauthor{Godlin09}~\cite{Godlin09}, to treat procedure call concretely in $\Vsemantics$ but abstractly in $\Asemantics$. The latter is a first ingredient in reflecting mutual summaries.
\item Execution of pairs of procedures is included in the operational semantics, modelled by the rules \composeRuleVerified{} and \composeRuleAbstract{}: \[\store_1,s_1 \parcomp \store_2,s_2 \exeEither[\tr_1,\tr_2] \store_3 \parcomp \store_4\] meaning statement $s_1$ executed on store $\store_1$ results in store $\store_3$ producing trace $\tr_1$, and similarly for statement $s_2$. These rules reflect product programs~\cite{Lahiri2012,Barthe2016,Banerjee2016}.
\item We require the program adhere to a specification given by $\Contract$\footnote{We expect single program contracts to have been verified; programs with no contracts are also acceptable.}.
\item The semantics are instrumented to produce a trace of the states reached during execution which we use to distinguish particular executions.
\item although our semantics is a big step semantics, we keep the whole calling context as part of the runtime configuration to allow us to give useful meaning to isomorphism of stores.
\item We assume loops will been encoded as recursive procedures.
\end{itemize}

We only discuss some of the rules of the operational semantics. \blNew{} allocates a new object.\footnote{In a concrete implementation we do not require that there is no garbage collection, just that the programmer cannot manipulate addresses.} The address of the object must be fresh, and the object has all fields set to \texttt{null}. \blAssign{} updates a stack variable $x$ with the result of evaluating an expression $e$ in the store $\store$.

\bodyRule{} executes the body of a procedure \texttt{\fun} by looking up and executing \texttt{\fun}'s statements. Our assumption that procedure contracts have already been verified, is modelled by the requirement $(\store_1,\store_3) \in \Contract(\fun)$. Note that \bodyRule{} pops the top of the final stack, while \callRuleAbstract{} and \callRuleVerified{} push new frames (using the function $\mkframe$).

\callRuleAbstract{} models abstraction of procedure calls. The behaviour of the abstracted call is restricted by the procedure's contract $\Contract(\fun)$, and the call may not free any allocated address (All that RIE actually requires is that the language not have concrete addresses so any language with garbage collection which does not support pointer arithmetic can be handled.)

Angelic allocation in the rule \composeRuleAbstract{} is modelled by the predicate over trace pairs $\isoR$. The behaviour of called procedures in the \asemantics{} is modelled by the predicate over trace pairs $\mutR$. We define $\isoR$ and $\mutR$, as the paper progresses.

\subsection{Isomorphism}

Stores are isomorphic if they differ only in the actual values of heap addresses or in garbage. An isomorphism is characterised by a bijection between values, $\pi$. \Cref{def:global isomorphism} says that $\store_1$ is isomorphic to $\store_2$ with relation $\pi$ iff the stacks of $\store_1$ and $\store_2$ are the same height; for each corresponding stack frame the same variables are defined; and $\pi$ is an injection. Where $\pi$ is the uniquely defined relation that maps the stack variables of $\store_1$ to $\store_2$, commutes with field dereference, and preserves the meaning of $\nullv$, $\truev$, and $\falsev$.

\newcommand*{\piv}{\pi_v}
\begin{definition}[Isomorphism]\label{def:global isomorphism}\setlength{\parindent}{0cm}~

	$\store_1\iso_\pi\store_2 \defiff$
	\begin{itemize}
		\item $\cardinality{\store_1} = \cardinality{\store_2} \band \forall i \le \cardinality{\store_1} \suchthat\domain{\store_1[i]} = \domain{\store_2[i]}$
		\item $\pi$ is an injection\footnote{$\bijection{\pi} \defiff \forall (a,b), (c,d) \in \pi \suchthat \left(a=c \iff b=d\right)$}, written $\bijection{\pi}$
	\end{itemize}

	Where $\pi$ is the smallest relation that satisfies:
		\[\begin{aligned}
		   \pi = &\piv \cup
		   \setcomp{\store_1[i](x)\mapsto\store_2[i](x)}{x \in \domain{\store_1[i]} \band i \le \cardinality{\store_1}} \cup \\
		   &\setcomp{\store_1(a,f)\mapsto\store_2(\pi(a),f)}{a \in \domain{\pi}}
		\end{aligned}\]
	And $\piv \defeq [\mathrm{\emph{\nullv}}\mapsto\mathrm{\emph{\nullv}}, \mathrm{\emph{\truev}}\mapsto\mathrm{\emph{\truev}}, \mathrm{\emph{\falsev}}\mapsto\mathrm{\emph{\falsev}}]$
\end{definition}

In our notation: The number of stack frames in store $\store$ is $\cardinality{\store}$. The value of variable $x$ in the $i^{\textit{th}}$ stack frame is $\store[i](x)$. The domain of the mapping $\pi$ is $\domain{\pi}$, and $\domain{\store[i]}$ is the set of variables defined in the $i^{\textit{th}}$ stack frame.

We also require that any contracts in the program are not sensitive to address values or garbage. We write $\qvars{\store}{i \ldots j}$ to mean $\store_i,\ldots,\store_j$.
\begin{definition}[Contracts in \lang{}]\label{def:contracts}
The contracts $\Contract: \PName \rightarrow \powerset{\Store \times \Store}$, are sets of pairs of $\Store$ representing the set of acceptable pre and post stores of each procedure. We require that:
\[\begin{aligned}
	&	\forall \fun,\qvars{\store}{1 \ldots 4},\qvars{\pi}{1,2} \suchthat
		\store_1 \iso_{\pi_1} \store_2 \band \store_3 \iso_{\pi_2} \store_4 \band (\store_1,\store_3) \in \Contract(\fun) \band \bijection{\pi_1 \cup \pi_2}  \\
	&\quad	\implies
		(\store_2,\store_4) \in \Contract(\fun)
\end{aligned}\]
\end{definition}

\begin{lemma}[Isomorphism is an equivalence relation]\label{lem:isomorphism is equivalence}
The relation $\iso$ is an equivalence relation (reflexive, symmetric, transitive)
\end{lemma}

The crucial property of \isoref{} is that it is closed under execution. Namely, executing a statement from isomorphic stores results in isomorphic executions. Executions are isomorphic iff the elements of their traces are pairwise isomorphic (written $\tr_1 \iso \tr_2$), and have isomorphic write effects.

\begin{lemma}[\lang{} closed under isomorphism]\label{lem:closed under isomorphism}\setlength{\parindent}{0cm}

For every execution $\store_1,s\exeEither[\tr_1]\store_3$, store $\store_2$, and injection $\pi_1$ if $\store_1 \iso_{\pi_1} \store_2$ then
\begin{itemize}
	\item there exists an execution $\store_2,s\exeEither[\tr_2]\store_4$
	\item if $\Lsemantics{}=\Vsemantics{}$, every execution $\store_2,s\exeVerified[\tr_2]\store_4$ is isomorphic to $\store_1,s\exeVerified[\tr_1]\store_3$
\end{itemize}

Executions $\store_1,s\exeEither[\tr_1]\store_3$ and $\store_2,s\exeEither[\tr_2]\store_4$ are \emph{isomorphic} iff $\exists \qvars{\pi}{1,2} \suchthat$
\[\begin{aligned}
\store_1 \iso_{\pi_1} \store_2 \band
  	\tr_1 \iso \tr_2 \band
	\bijection{\pi_1\cup\pi_2} \band
	\diff(\store_1,\store_3) \iso_{\pi_2} \diff(\store_2,\store_4)
\end{aligned}\]

Where trace isomorphism is:
\[\begin{aligned}
\tr_1 \iso \tr_2 &\defiff \tr_1 \iso_\emptyset \tr_2 \\
\tr_1 \iso_\pi \tr_2 &\defiff \exists n \suchthat
	\cardinality{\tr_1}=\cardinality{\tr_2}=n \band \exists \pi_1\ldots\pi_{2n}\suchthat \\
&\quad	(\forall i \le n \suchthat \tr_1[i]\evalat_{2}\iso_{\pi_{2i-1}}\tr_2[i]\evalat_{2}) \band \\
&\quad	(\forall i \le n \suchthat \tr_1[i]\evalat_{3}\iso_{\pi_{2i}}\tr_2[i]\evalat_{3}) \band \\
&\quad	(\forall i,j \le 2n \suchthat \bijection{\pi \cup \pi_i \cup \pi_j})
\end{aligned}\]

And where $\diff(\store_1,\store_3) \defeq \heapof{\store_3} \setminus \heapof{\store_1}$
\end{lemma}
\begin{proof}By induction on the derivation of $\store_1,s\exeEither[\tr_1]\store_3$. Most cases are straightforward since no instruction is sensitive to the actual value of addresses. Note that every instruction makes the set of reachable addresses smaller, apart from $\news$ which expands it by exactly one fresh address --- this corresponds to the fact that addresses are never synthesised and garbage is never resurrected.\qed\end{proof}

A way to think of \ncui{} is that \lang{} is not sensitive to the actual values of addresses nor garbage. Many industrial languages (such as C, Java, Python, C$^\sharp$, etc) contain features that are sensitive to the actual values of heap addresses or order of allocation. Such sensitivity is typically not central to the language and it is often not necessary to use such features.

\subsection{Regional Isomorphism}

As discussed in \Cref{sec:impl}, \Tool{} works by establishing isomorphisms between the heap regions reachable from procedure parameters (\Cref{lst:summary axiom antecedent} of \Cref{fig:mutual summary}), so we introduce a notion of isomorphism between heap regions. The heap regions reachable from two sequences of parameter names $W$ and $X$ are isomorphic iff the sequences have the same length, and the relation ($\pi$) constructed by following all paths from the parameters is an injection:

\begin{definition}[Regional Isomorphism]\label{def:regional isomorphism}\setlength{\parindent}{0cm}~

\[\begin{aligned}
&	\store_1\wiso_{\pi}^{W,X}\store_2 \defiff \\
&\quad	\cardinality{W} = \cardinality{X} \band W \subseteq \domain{\topof{\store_1}} \band X \subseteq \domain{\topof{\store_2}} \band \bijection{\pi}
\end{aligned}\]
	Where $\pi$ is the smallest relation which satisfies:
		\[\begin{aligned}
		   \pi = &\piv \cup
		   \setcomp{\store_1(W[i])\mapsto\store_2(X[i])}{i \le \cardinality{X}} \cup
		   \setcomp{\store_1(a,f)\mapsto\store_2(\pi(a),f)}{a \in \domain{\pi}}
		\end{aligned}\]
\end{definition}

\subsection{Procedure Equivalence}

Procedures are equivalent if executing their bodies from isomorphic stores results in isomorphic stores. Executing $\body~\fun$ means looking up and executing the statements that form the body of procedure $\fun$. Note that rule \bodyRule{} pops the top stack frame before completing, so stores $\store_3,\store_4$ in \Cref{def:procedure equivalence} are as observed by a caller. This means that equivalence relates to the observable behaviour of the procedure body, and that differences in local variables, etc, are ignored. The same definition of procedure equivalence applies to both the $\Asemantics$ and the $\Vsemantics$ semantics.

\begin{definition}[Procedure equivalence]\label{def:procedure equivalence}\setlength{\parindent}{0cm}
\[\begin{aligned}
&\fun_1 \isol \fun_2 \defiff \\
&\quad\forall \qvars{\store}{1 \ldots 4} \suchthat
	\store_1 \iso \store_2 \band
        \store_1,\body~\fun_1 \parcomp \store_2,\body~\fun_2 \exeEither \store_3 \parcomp \store_4
	\implies
	\store_3 \iso \store_4
\end{aligned}\]
\end{definition}

\subsection{Angelic Allocation}

We describe how angelic allocation is modelled by the predicate $\isoR$ in the \asemantics{} rule \composeRuleAbstract{}. The predicate selects the pairs of execution traces that exhibit desirable allocation patterns.

Predicate $\isoR$ (\Cref{def:my compatible isomorphic states}) retains only traces with heap regions that are equal at particular isomorphic points (\Cref{def:isomorphic points}) in the traces. In \tool{}, these points correspond to procedure entry, equivalent procedure calls and allocation sites. \tool{} only verifies procedures from equal (rather than isomorphic) initial stores, discards execution pairs which don't have interesting correspondences between allocations, and assumes procedures have equal effects. Because we are only trying to prove soundness of \metho{}, it is not necessary to fully specify how \tool{} chooses which stores to equate. Rather, we prove that \emph{any} assumption of store equality that the tool makes is sound, subject to the caveats in \Cref{def:isomorphic points}.

\begin{definition}[Isomorphic Points]\label{def:isomorphic points}\setlength{\parindent}{0cm}
	
	Any tool using \metho{} must define a function
	\[\myIsoCompatibleStates : (\Trace\times\Trace) \rightarrow \powerset{\nat \times \nat \times \LVar^* \times \LVar^*}\]
	with the following properties:
	\begin{enumerate}
		\item The same set of points is produced for isomorphic traces:
		\[
			\forall \qvars{\tr}{3,4} \suchthat \tr_1\iso\tr_3 \band \tr_2\iso\tr_4
			\implies \myIsoCompatibleStates(\tr_1,\tr_2) = \myIsoCompatibleStates(\tr_3,\tr_4)
		\]
		\item The traces are isomorphic at each of the points:
		\[\begin{aligned}
			&\forall (i,j,W,X)\in \myIsoCompatibleStates(\tr_1,\tr_2) \suchthat \exists \pi_1 \suchthat \tr_1[i] \wiso_{\pi_1}^{W,X} \tr_2[j]
		\end{aligned}\]
		\item If the initial stores of $\tr_1,\tr_2$ are isomorphic, then the isomorphism is injective with all the other isomorphisms. Otherwise the isomorphisms are empty.
		\begin{itemize}
			\item $\bijection{\pi \cup \Pi(\tr_1,\tr_2)}$
			\item $\nexists \pi \suchthat \first{\tr_1} \iso_{\pi} \first{\tr_2} \implies \Pi(\tr_1,\tr_2) = \emptyset$
		\end{itemize}
	\end{enumerate}
	Where
	\[\begin{aligned}
		\Pi(\tr_1,\tr_2) = \bigcup\setcomp{\pi}{\exists (i,j,X,Y) \in \myIsoCompatibleStates(\tr_1,\tr_2) \band \tr_1[i] \wiso_{\pi}^{X,Y} \tr_2[j]}
	\end{aligned}\]
\end{definition}

\begin{definition}[Angelic Allocation]\label{def:my compatible isomorphic states}\setlength{\parindent}{0cm}
\[\isoR(\tr_1,\tr_2) \defiff \Pi(\tr_1,\tr_2) \subseteq \identity\]
\end{definition}

\Cref{def:isomorphic points} requires that the points are selected symmetrically for isomorphic traces. This symmetry is critical for the soundness of \metho{}, which must verify at least one pair of execution traces for each initial state. Furthermore, the definition requires that the union of the isomorphisms between the selected heap regions is an injection. This corresponds to the fact that \metho{} is implemented by equating allocation sites, and will be discussed further in later sections, particularly \Cref{sec:discussion}.

\subsection{Mutual Summaries of Equivalent Procedures}\label{sec:mutual}

\tool{} uses mutual summaries, \cref{lst:summary axiom start,lst:summary axiom end} in \Cref{fig:mutual summary}, to allow the verifier to use facts about the behaviour of equivalent procedure calls in its proofs. It is needed in order for procedure equivalence to be a transitive relation.

\tool{}'s use of mutual summaries is modelled by the rule \callRuleAbstract{}, which overapproximates the behaviour of concrete procedure call. And the predicate $\mutR$ in the rule \composeRuleAbstract{}, which restricts the traces to those where the procedure pairs in $\equivmap$ behave equivalently.

The antecedent $\store_1 \wiso_{\pi_1}^{\{x_1 \ldots x_n\},\{y_1 \ldots y_n\}} \store_2$ expresses that the regions reachable from the parameters are isomorphic (as needed for \ctwo{}), while the conclusion $\diff(\store_1,\store_3) \iso_{\pi_2} \diff(\store_2,\store_4)$ expresses that the procedures have isomorphic write effects (as needed for \cthree{}). In our example, the encoding of the antecedent is \texttt{\$Heap\#EqualFromParams} on \cref{lst:summary axiom antecedent} of \Cref{fig:mutual summary}, while the encoding of the conclusion is \texttt{\$SameDiff} on \cref{lst:summary axiom consequent} of \Cref{fig:mutual summary}.

\begin{definition}[Mutual Summaries of Equivalent Procedures]\label{def:mutual summary}\setlength{\parindent}{0cm}
\[\begin{aligned}
\mutR(\tr_1,\tr_2) \defiff
&\forall \pi_1,\qvars{\store}{1 \ldots 4},(\fun_1,\fun_2) \in \equivmap \suchthat \\
&\quad		(\call~\fun_1(x_1 \ldots x_n),\store_1,\store_3) \in \tr_1 \band \\
&\quad		(\call~\fun_2(y_1 \ldots y_n),\store_2,\store_4) \in \tr_2 \band \\
&\quad		\store_1 \wiso_{\pi_1}^{\{x_1 \ldots x_n\},\{y_1 \ldots y_n\}} \store_2 \\
&	\implies
 	\exists \pi_2 \suchthat \bijection{\pi_1 \cup \pi_2} \band \diff(\store_1,\store_3) \iso_{\pi_2} \diff(\store_2,\store_4)
\end{aligned}\]
\end{definition}

\subsection{Soundness of \metho{}}

We now give the theorem which guarantees soundness of \metho{}, and describe some keys points in its proof. Theorem~\ref{lem:tool is sound} states that if all pairs in $\equivmap$ are mutually terminating and equivalent under the \asemantics{}, then they are also equivalent under the \vsemantics{}. Mutual termination ($\muttermname$) means that both procedures terminate for the same set of initial stores\footnote{We could produce a total definition of procedure equivalence by including a notion of mutual termination~\cite{Hawblitzel2013,Elenbogen2015} in \Cref{def:procedure equivalence}. However, \tool{} does not yet reason about the termination behaviour of the procedures. A total notion of procedure equivalence is important, particularly where a transitive procedure equivalence relation is needed. Since our tool takes the same basic approach as Symdiff, it should be straightforward to incorporate existing mutual termination checking techniques~\cite{Godlin08,Hawblitzel2013,Elenbogen2015}.}.

\begin{theorem}[\metho{} is sound]\label{lem:tool is sound}\setlength{\parindent}{0cm}

\[\begin{aligned}
&\text{If }\forall (\fun_3,\fun_4) \in \equivmap \suchthat \mutterm{\Vsemantics}{\fun_3}{\fun_4} \band \fun_3 \isoa \fun_4 \\
&\text{Then }\forall (\fun_1,\fun_2) \in \equivmap \suchthat \fun_1 \isov \fun_2
\end{aligned}\]

Where $\mutterm{\Lsemantics}{\fun_3}{\fun_4} \defiff \forall \qvars{\store}{1 \ldots 3} \suchthat \store_1 \iso \store_2 \implies$
\[\begin{aligned}
&	\left(\store_1,\body~\fun_3\exeEither\store_3 \implies \exists \store_4 \suchthat \store_2,\body~\fun_4\exeEither\store_4\right) \band \\
&	\left(\store_1,\body~\fun_4\exeEither\store_3 \implies \exists \store_4 \suchthat \store_2,\body~\fun_3\exeEither\store_4\right)
\end{aligned}\]
\end{theorem}
\def\tagone{(1)}
\def\tagtwo{(2)}
\def\tagthree{(3)}
\def\tagfour{(4)}
\def\tagfive{(5)}
\def\tagsix{(6)}
\def\sublemmaone{(l1)}
\begin{proof}
The proof proceeds by showing that for any pair of executions ($\tr_1,\tr_2$) from isomorphic initial stores in the \vsemantics{} there exist an isomorphic execution ($\tr_5$ with $\tr_1\iso\tr_5$) such that that $\isoR$ and $\mutR$ hold for $(\tr_1,\tr_5)$ and thus the $\tr_5$ and $\tr_2$ executions compose by $\parcomp$ in the \asemantics{}.
%
Then by the assumptions and transitivity of \isoref{} we know that $\tr_1,\tr_2$ end in isomorphic stores.
%
The proof goes by an inner induction nested within an outer induction. We now write the proof in some more detail:

Assume $\forall (\fun_3,\fun_4) \in \equivmap \suchthat \mutterm{\Vsemantics}{\fun_3}{\fun_4} \band \fun_3 \isoa \fun_4$.

To show:
\[\begin{aligned}
&\forall (\fun_1,\fun_2) \in \equivmap, \qvars{\store}{1 \ldots 4}, \qvars{\tr}{1,2} \suchthat  \\
&\quad	\store_1 \iso \store_2 \band
        \store_1,\body~\fun_1 \parcomp \store_2,\body~\fun_2 \exeVerified[\tr_1,\tr_2] \store_3 \parcomp \store_4
	\implies
	\store_3 \iso \store_4
\end{aligned}\]

%By induction on the depth of the derivation $\store_1,\body~\fun_1\exeVerified[\tr_1]\store_3$
%
%The I.H. should look like
%\[\begin{aligned}
%&\forall (\fun_1,\fun_2) \in \equivmap, \qvars{\store}{5 \ldots 8}, \qvars{\tr}{3,4} \suchthat  \\
%&\quad	\cardinality{\store_5,\body~\fun_3\exeVerified[\tr_3]\store_7} < \cardinality{\store_1,\body~\fun_1\exeVerified[\tr_1]\store_3} \\
%&\quad	\implies \\
%&\qquad	\store_5 \iso \store_6 \band
%        \store_5,\body~\fun_3 \parcomp \store_6,\body~\fun_4 \exeVerified[\tr_3,\tr_4] \store_7 \parcomp \store_8
%	\implies
%	\store_7 \iso \store_8
%\end{aligned}\]

\textbf{First part}: From \Cref{def:isomorphic points} we see that there is a $\pi_2=\Pi(\tr_1,\tr_2)$ \tagone{}.
%
By \Cref{lem:sufficient non-determinism} (below) there exists a third execution $\store_2,\body~\fun_1\exeVerified[\tr_3]\store_5$ such that $\tr_1$ is isomorphic to $\tr_3$ with $\pi_2$, \ie $\tr_1\iso_{\pi_2}\tr_3$, which means by \Cref{lem:isomorphism is equivalence} (symmetry) we get $\tr_3\iso_{\pi^{-1}_2}\tr_1$ \tagtwo{}.
%
Take any point $(i,j,X,Y) \in \myIsoCompatibleStates(tr_1, tr_2)$. To show: $\tr_3[i] \wiso_{\identity}^{X,Y} \tr_2[j]$.
%
By \tagone{} exists $\pi_4$ such that $\tr_1[i] \wiso_{\pi_4}^{X,Y} \tr_2[j]$ and $\pi_4 \subseteq \pi_2$ \tagfour{}.
%
By \tagtwo{} there exists $\pi_3$ such that $\tr_3[i] \iso_{\pi_3} \tr_1[i]$ and $\pi_3 \subseteq \pi_2^{-1}$ \tagthree{}.
%
Hence, by \Cref{lem:isomorphism is equivalence} (transitivity), we have that $\tr_3[i] \wiso_{\pi_3 \circ \pi_4}^{X,Y} \tr_2[j]$, we know $\pi_3$ composed with $\pi_4$ is large enough because $X$ is a subset of the stack variables defined in $\tr_1[i]$, and $\domain{\pi_3}$ includes the values of all stack variables.
%
By \tagthree{}, \tagfour{}, we know that $\pi_3$ composed with $\pi_4$ is a subset of the identity relation. So $\tr_3[i] \wiso_{\identity}^{X,Y} \tr_2[j]$.
%
Because $\tr_1\iso\tr_3$ we have by definition $\myIsoCompatibleStates(tr_1, tr_2)=\myIsoCompatibleStates(tr_3, tr_2)$. Then we get $\forall (i,j,X,Y) \in \myIsoCompatibleStates(tr_3, tr_2) \suchthat \tr_3[i] \wiso_{\identity}^{X,Y} \tr_2[j]$. And thus we have $\Pi(\tr_3,\tr_2) \subseteq \identity$, which in turn gives us $\isoR(\tr_3,\tr_2)$ \tagfive{}.

\noindent\textbf{Second part}: We now proceed by induction on the size of the derivation of $\store_2,\body~\fun_1 \exeVerified[\tr_3] \store_5$.

It remains to show that, $\tr_2$ is also a trace under $\Asemantics$ and that there is an $\Asemantics$ trace $\tr_5$ isomorphic to $\tr_3$ such that $\mutR(\tr_5,\tr_2)$ holds.
%
Note that it is trivial to prove that apart from $\parcomp$ all the rules of \asemantics{} overapproximate the \vsemantics{} \sublemmaone{}.
%
By \sublemmaone{} and induction on the derivation of $\store_2,\body~\fun_2\exeVerified[\tr_2]\store_4$ we get $\store_2,\body~\fun_2\exeAbstract[\tr_2]\store_4$.

\noindent\textbf{Base case}: there are no procedure calls in $\store_1,\body~\fun_1\exeVerified[\tr_1]\store_3$.
%
By \Cref{lem:closed under isomorphism} then $\store_2,\body~\fun_1\exeVerified[\tr_3]\store_5$ also has no procedure calls.
%
By \sublemmaone{} and induction on the derivation of $\store_2,\body~\fun_1\exeVerified[\tr_3]\store_5$ we get $\store_2,\body~\fun_1\exeAbstract[\tr_3]\store_5$.
%
Since there are no procedure calls, trivially $\mutR(\tr_3,\tr_2)$  and $\store_2,\body~\fun_1 \parcomp \store_2,\body~\fun_2 \exeAbstract[\tr_3,\tr_2] \store_5 \parcomp \store_4$.
%
From the antecedent we know that $\last{\tr_3}\iso\last{\tr_2}$, and since $\tr_1\iso\tr_3$ then by transitivity of $\iso$ we have $\last{\tr_1}\iso\last{\tr_2}$. And since $\last{\tr_1}=\store_3$ and $\last{\tr_2}=\store_4$ base case is done.

\noindent\textbf{Inductive step}: there are procedure calls in $\store_1,\body~\fun_1\exeVerified[\tr_1]\store_3$.
\begin{itemize}
\item[] To show: there exists an execution $\store_2,\body~\fun_1\exeAbstract[\tr_5]\store_7$ such that $\mutR(\tr_5,\tr_2)$ and $\tr_5\iso_\identity\tr_3$ \tagsix{}.
%
Proceed by an inner induction over the derivation of $\store_2,\body~\fun_1\exeVerified[\tr_3]\store_5$.
%
Most cases are trivial. The interesting cases are \callRuleVerified{} where the called procedure is in $\equivmap$, and the inductive case \blTrans{}.

\noindent\textbf{Inner case} \callRuleVerified{} where the called procedure is in $\equivmap$.
%
By case there is $\store_2,\call~\fun_3(x_1 \ldots x_n) \exeVerified\store_5$ and $(\fun_3,\fun_4) \in \equivmap$.
%
Rule \callRuleVerified{} can only be applied if a shallower tree is derivable for the body of the called procedure. Therefore we apply the outer induction hypothesis, the antecedent $\mutterm{\Vsemantics}{\fun_3}{\fun_4}$, and \Cref{lem:sufficient non-determinism}, to deduce that there exists $\store_7$ such that $\store_2,\call~\fun_4(x_1 \ldots x_n) \exeVerified[\tr_5]\store_7$ and $\store_5\iso_{\identity}\store_7$. From \callRuleAbstract{} we see that $\store_2,\call~\fun_3(x_1 \ldots x_n) \exeAbstract[(\call~\fun_3(x_1 \ldots x_n),\store_2,\store_7)]\store_7$ (intuition: we swap the behaviour of $\fun_3$ for the behaviour of $\fun_4$). Take $\tr_5=(\call~\fun_3(x_1 \ldots x_n),\store_2,\store_7)$ and we have $\tr_3\iso_{\identity}\tr_5$.
%
To show: $\mutR(\tr_5,\tr_2)$. Take arbitrary $(\call~\fun_4(y_1 \ldots y_n),\store_8,\store_{10}) \in \tr_2$ such that
$\store_2 \wiso_{\pi_5}^{\{x_1 \ldots x_n\},\{y_1 \ldots y_n\}} \store_8$. To show: $\exists \pi_6 \suchthat \bijection{\pi_5 \cup \pi_6} \band \diff(\store_2,\store_5) \iso_{\pi_6} \diff(\store_8,\store_{10})$. This follows straightforwardly from \Cref{lem:closed under isomorphism} and the fact that the same procedure $\fun_4$ was executed to obtain $\store_5$ as to obtain $\store_{10}$. Inner case \textbf{done}.

\noindent\textbf{Inner case} \blTrans{}
%
By case there is $\store_2,s_1;s_2 \exeVerified[\tr_3]\store_5$ and hence exists $\store_9,\qvars{\tr}{7,9}$ such that $\store_2,s_1 \exeVerified[\tr_7]\store_9,s_2 \exeVerified[\tr_9]\store_5$. The proof goes as expected, by applying the inner induction hypothesis twice with one slight complexity. The first application constructs another execution of $s_1$ with the desired properties; but that execution's final store is not $\store_9$! Rather it is some other store (say $\store_{11}$) that is isomorphic to $\store_9$. Before we apply the inner induction hypothesis a second time, we use \Cref{lem:sufficient non-determinism} to construct an execution isomorphic to $\store_9,s_2 \exeVerified[\tr_9]\store_5$ but with initial store $\store_{11}$. $\mutR$ holds for the resultant traces by the same argument as the \callRuleVerified{} case. Inner case \textbf{done}.

Hence $\mutR(\tr_5,\tr_2)$. From \tagfive{} and \tagsix{} we also have $\isoR(\tr_5,\tr_2)$. So we get that $\store_2,\body~\fun_1\parcomp\store_2,\body~\fun_2\exeAbstract[\tr_5,\tr_2]\store_7\parcomp\store_4$ is an execution under the \asemantics{}.
%
Finally, from the antecedent we know that $\last{\tr_3}\iso\last{\tr_4}$, and since $\tr_1\iso\tr_3\iso\tr_5$ and $\tr_2\iso\tr_4$ then by transitivity of $\iso$ we have $\last{\tr_1}\iso\last{\tr_2}$. And since $\last{\tr_1}=\store_3$ and $\last{\tr_2}=\store_4$ we are done.
%
\end{itemize}\qed\end{proof}

The soundness proof of \Cref{lem:tool is sound} relies on constructing alternative executions that are isomorphic using the identity bijection, \Cref{lem:sufficient non-determinism} states that all such alternative executions are derivable in \lang{}.

\begin{lemma}[Sufficent non-determinism]\label{lem:sufficient non-determinism}\setlength{\parindent}{0cm}
Given statement $s$, stores $\qvars{\store}{1 \ldots 3}$, mapping $\pi_1$, and alternative allocation strategy $\qvars{\pi}{2}$, such that:
\begin{itemize}
	\item $\store_1$ and $\store_2$ are isomorphic with mapping $\pi_1$: $\store_1 \iso_{\pi_1} \store_2$
	\item $s$ can execute to completion from $\store_1$: $\store_1,s\exeEither[\tr_1]\store_3$
	\item $\pi_1$ and $\pi_2$ map common addresses in the same way $\bijection{\pi_1 \cup \pi_2}$
	\item %$\pi_2$ doesn't map between allocated and unallocated addresses
		$\forall (a_1,a_2) \in \pi_2 \suchthat (a_1 \in \heapof{\store_1} \iff a_2 \in \heapof{\store_2})$
\end{itemize}

Then there exists an isomorphic execution $\store_2,s\exeEither[\tr_2]\store_4$ such that:
	\[\tr_1 \iso_{\pi_2} \tr_2 \band \forall (a_1,a_2) \in \pi_2 \suchthat (a_1 \in \heapof{\store_3} \iff a_2 \in \heapof{\store_4})\]
\end{lemma}
\begin{proof}By induction on the derivation of $\store_1,s\exeEither[\tr_1]\store_3$ the alternative execution is constructed. In particular note that because $\pi_2$ does not map between allocated and unallocated addresses, the appropriate alternative address is always unallocated when an allocation statement is reached. And that, since $\bijection{\pi_1 \cup \pi_2}$ then all addresses that were already allocated at the start of the execution do not need to be allocated alternatives. The proof goes through for both $\Vsemantics$ and $\Asemantics$.
\qed\end{proof}

\section{Discussion}\label{sec:discussion}

The number of correspondences between allocations (\Cref{sec:impl}) is factorial in the maximum number of allocation sites in either procedure. Hence \metho{} is only practical for relatively small numbers of allocation sites. However, this is not as restrictive as it may seem because our approach is modular. In practice, when loops are encoded as procedure calls, then many interesting procedures contain only small numbers of allocations. In some cases it is also possible to split a procedure into chunks or abstract common parts. It is also likely that the applicability of this technique can be significantly extended by using additional static analysis to eliminate some of the permutations in advance. For example, the types of the objects being allocated could be used to eliminate permutations that aligned objects of different types.

Framing of procedure calls is important in verifying equivalence for many examples. \Tool{} has a fairly naive approach to framing and disjointness of heap regions, which restricts the class of examples it can currently deal with. However, our techniques, and choice of Dafny~\cite{Leino10} style heap encoding, should be amenable to a more powerful framing methodology. Improving \tool{}'s framing support is likely to significantly improve its completeness.

We considered many alternative approaches to establishing isomorphism. The natural approach using existentials does not work very well. We investigated several approaches using universal quantification. We tried defining heaps to be isomorphic if all pairs of paths that lead to related addresses in one heap also lead to related addresses in the other. We tried several approaches for limiting which, and what depth of paths should be considered by the solver. But the underlying doubly exponential complexity of comparing all pairs of paths impedes the applicability of that approach. The requirement that disjoint heap effects of procedure calls commute was an important design force: many alternative approaches required extensive additional axioms to handle the various cases, whereas our current approach of enumerating allocators seems to handle many cases naturally.

\subsection{Examples}


There are a collection of programs available from \url{https://github.com/lexicalscope/ape#automatic-procedure-equivalence-tool} that show the capabilities of \tool{}. Several of them have been listed in \Cref{fig:progs} with timings performed on an Intel Core i5-3210M@2.5GHz processor with 8GB memory.

\begin{figure}[htbp]
\centering%
\begin{tabular}{| l | c |  }

\hline	
  {\bf Description} & {\bf Timing}\\
\hline
  Empty program & 1.5s \\		
  Change order of allocation & 1.5s  \\
  Change amount of garbage allocated & 1.5s  \\
  Making the same procedures calls & 1.5s \\
  Isomorphism of heap reachable from call parameters & 1.8s \\
  Allocations moved past calls & 1.5s \\
  Recursive calls reordered & 8s \\
  Copying a cyclic data structure & 4s \\
  Inserting a row into a table  & 31s \\
  Copying a list & 7s \\
  Copying a tree & 130s  \\
  \hline  

\end{tabular}
\caption{Examples with timings}\label{fig:progs}
\end{figure}
\metho{}'s approach of using equality to establish isomorphism does prevent \tool{} from establishing isomorphism in some cases where it would be helpful to do so. The example in \Cref{fig:listex} is from a refactoring of some code which manipulates a doubly linked list. Both procedures add an element to a list, but first remove it if it is already present. The left procedure has a redundant check that the item is in the list, in the right procedure this redundancy is removed.

The isomorphism between lines~\ref{lst:listex find one} and~\ref{lst:listex' find} relates the addresses in \texttt{rf0} and \texttt{rf}. The isomorphism between lines~\ref{lst:listex find two} and~\ref{lst:listex' find} relates the addresses in \texttt{rf1} and \texttt{rf}. If we were to assume equality for both of these isomorphisms then we would have $\texttt{rf} = \texttt{rf0} = \texttt{rf1}$. However, \texttt{rf0} is allocated by the \texttt{new} statement on line~\ref{lst:listex new one} whereas \texttt{rf1} is allocated by the subsequent \texttt{new} statement on line~\ref{lst:listex new two}. The semantics of \texttt{new} require that each allocation gives an address which was not previously allocated --- \ie that $\texttt{rf0} \neq \texttt{rf1}$.

\metho{}, therefore, restricts the selected points in \Cref{def:my compatible isomorphic states} to prevent contradictory isomorphisms being selected. Due to this restriction a verifier using \metho{} alone may fail to produce a proof for some procedures that are in fact equivalent according to our definitions. Any tool using \metho{} in practice may choose to equate one pair of calls to \texttt{find}, but it must find some other way to deal with the other pair of calls (such as manually adding an additional specification of \texttt{find}). 

\begin{figure}[htbp]
\noindent\begin{minipage}{.48\textwidth}
\begin{lstlisting}[style=bl,name=copyex,firstnumber=auto]
new rf0;Â£\label{lst:listex new one}Â£
find(l,x,rf0);Â£\label{lst:listex find one}\tikzmark{ladd1}Â£
if(!rf0.v.sentinel) {Â£\label{lst:listex if one}Â£
  new rf1;Â£\label{lst:listex new two}Â£
  find(l,x,rf1);Â£\label{lst:listex find two}\tikzmark{ladd2}Â£
  node := rf1.v;
  if (!node.sentinel) {Â£\label{lst:listex if two}Â£
    node.prev.next := node.next;
    node.next.prev := node.prev;
  }
  add(l,x);
} else {
  add(l,x);
}
Â£~Â£
find(l,x,r) modifies {r} ...
add(l,x) ...
\end{lstlisting}
\end{minipage}%
\begin{minipage}{.48\textwidth}
\begin{lstlisting}[style=bl,name=copyex,firstnumber=auto]
new rf;
Â£\tikzmark{radd1}Â£find(l,x,rf);Â£\label{lst:listex' find}Â£
Â£~Â£
Â£~Â£
Â£~Â£
node := rf.v;
if(!node.sentinel){Â£\label{lst:listex' if}Â£
  node.prev.next := node.next;
  node.next.prev := node.prev;
}
add(l,x);
Â£~Â£
Â£~Â£
Â£~Â£
Â£~Â£
find(l,x,r) modifies {r} ...
add(l,x) ...
\end{lstlisting}
\end{minipage}%
\caption{A difficult example where two stores in one execution are isomorphic with the same store in the other execution\label{fig:listex}.}%
\begin{tikzpicture}[overlay,remember picture]
\draw[black,dashed] (ladd1) -- (radd1);
\draw[black,dashed] (ladd2) -- (radd1);
\end{tikzpicture}%
\end{figure}

\subsection{Definitions of Isomorphism and Procedure Equivalence}

Our definition of procedure equivalence is useful because it is a contextual equivalence~\cite{Milner1977} for \lang{}. This means that given equivalent procedures $\fun_1,\fun_2$ and a program that calls $\fun_1$, one can always change the program to call $\fun_2$ instead without affecting the observable behaviour of the program.  Of particular interest to programmers is \Cref{lem:assertion preserving}: the relation \isoref{} preserves the meaning of all assertions.

\begin{corollary}[Isomorphism is assertion preserving]\label{lem:assertion preserving}
	\[\begin{aligned}
		&\forall \store_1,\store_2,b \suchthat \store_1 \iso \store_2  \implies (\store_1\vDash{b} \iff \store_2\vDash{b})
	\end{aligned}\]
\end{corollary}
\begin{proof}Follows from \Cref{lem:closed under isomorphism}\qed\end{proof}

Interestingly, it is possible to define isomorphism almost equivalently as the least-fixed-point interpretation of the relation:
\[\begin{aligned}
&	\store_1\iso'\store_2 \defiff \\
&\quad		\store_1=\store_2=\store_\emptyset \bor
		\left(\exists s_a,\qvars{\store}{3,4} : \store_3\iso'\store_4 \band \store_3,s_a\exe\store_1 \band \store_4,s_a\exe\store_2\right)
\end{aligned}\]
where $\store_\emptyset$ is the empty store. That is, it could be defined as a smallest relation closed under the atomic operations of the semantics. However, even though the semantics is naturally closed under $\iso'$, the definition is not as helpful when trying to decide if a particular pair of stores are isomorphic. Regardless, a definition in this least-fixed-point style would allow us to construct a notion of isomorphism even for a semantics where we did not know an appropriate direct definition. Perhaps it is interesting to consider what assertion language would be preserved for any particular semantics given such a definition.

\subsection{Reachability}\label{sec:reachability}

Establishing reachability enables \tool{} to prove interesting examples, but is ancillary to the focus of this paper \metho{} and angelic allocation. Still, our definition of equivalence allows differences in garbage (which is unreachable memory), and \tool{} use reachability to reason about read and write effect framing as described in \Cref{sec:recursion} --- so an useful axiomatisation of reachability is needed.

\begin{figure}[htbp]%
\centering%
\noindent\begin{lstlisting}[style=Boogie,firstnumber=auto,name=copyex]
// Reachability is uninterpreted but axiomatised
function $Reach($h:Heap, $a:Ref, $b:Ref) : bool;

axiom (forall $h:Heap, $a:Ref :: $Reach($h, $a, $a));
axiom (forall $h:Heap, $a,$b:Ref :: {...}
 $Reach($h, $a, $b) && $NoInboundEdges($h,$b) ==> $a == $b);
axiom (forall $h:Heap, $a,$b:Ref :: {...} $Reach($h,$a,$b) ==> Â£\label{lst:reach ingoing}Â£
 $a == $b ||
 (exists $c:Ref,$f:Field Ref :: $Reach($h, $a, $c) && $Edge($h, $c, $f, $b)));
axiom (forall $h:Heap, $a,$b:Ref :: {...} $Reach($h,$a,$b) ==> Â£\label{lst:reach outgoing}Â£
 $a == $b ||
 (exists $c:Ref,$f:Field Ref :: $Edge($h, $a, $f, $c) && $Reach($h, $c, $b)));

function $NoInboundEdges($h:Heap, $a:Ref) : bool
 { (forall $b:Ref, $f:Field Ref :: !$Edge($h,$b,$f,$a)) }
\end{lstlisting}
\caption{The partial axiomatisation of reachability used by \tool{}, written in Boogie. The triggers are elided \texttt{\{...\}}. The function \texttt{\$Read(h,a,f)} is the value of field \texttt{f} of object \texttt{a} in heap \texttt{h}, the predicate \texttt{\$Allocated(\$h,\$a)} holds if object \texttt{\$a} is allocated in heap \texttt{\$h}. The predicate \texttt{\$Edge(\$h, \$a, \$f, \$c)} holds if the field \texttt{\$f} of object \texttt{\$a} has the value \texttt{\$c} in heap \texttt{\$h}.\label{fig:reachability}}
\end{figure}
\Cref{fig:reachability} shows our Boogie encoding of reachability. We give several axioms for the predicate \texttt{\$Reach}, which the tool instantiates in different circumstances controlled by various triggers (controlled programatically, users cannot write them). Rather than precisely deciding the reachability set, often it is necessary to prove disjointness of certain heap regions. For example, garbage objects are disjoint from the reachable region, and a property of a region is preserved over a procedure call if the region is disjoint from the call effects. Our choice of axioms enable the tool to establish a lack of reachability by showing either that there are no outgoing (\cref{lst:reach outgoing}) or no incoming (\cref{lst:reach ingoing}) edges to a particular heap region. Although the axioms \cref{lst:reach ingoing} and \cref{lst:reach outgoing} are logically equivalent, we use triggers to unroll them in different situations.
\section{Related Work and Conclusions}\label{sec:related}
The study of program equivalence arguably pre-dates the study of functional correctness. In his 1969 paper~\cite{Hoare1969}, \citeauthor{Hoare1969} identified that ``Many [previous] axiomatic treatments of computer programming~\cite{Yanov1958,Igarishi1964,DeBarker1968} tackle the problem of proving the equivalence, rather than the correctness, of algorithms''. To date, practical approaches to program equivalence rely on structural similarity of the programs. Many works focus on methods to account for some structural differences. The importance of program structure in proving program equivalence was observed by Dijkstra in 1972~\cite{Dahl1972}, where he also observes that programmers are often called upon to modify existing programs.
Key developments in program equivalence have come from research into \emph{non-interference} in \emph{secure information flow} and compiler \emph{translation validation}. Non-interference is the property that the values of secret inputs do not influence public outputs. Translation validation provides assurances that the program output by a compiler is correct with respect to the input program. Translation validation concerns itself with correctness of particular compiler runs, and does prove the compiler implementation correct.
Non-interference can be formalised in terms of program equivalence~\cite{Joshi2000}, or more generally as a safety property over pairs of program traces~\cite{Barthe2004,Terauchi2005}.  Methods for reducing safety properties over trace pairs to safety properties over single traces have been explored~\cite{Leino2008a,Benton2006} and generalised, particularly via product programs~\cite{Barthe2011,Barthe2013} and similar~\cite{Zaks2008,Stepp11,Tristan11}. \emph{Product programs} combine a pair of programs into one, such that useful invariants can be formulated at interesting points in the product, and can generalise to relations between programs~\cite{Barthe2016}.
Compiler translation validation~\cite{Kundu09,Stepp11,Tristan11,Le2014,Zaks2008} is inherently a program equivalence question. Many techniques have been applied, several variations of product programs~\cite{Zaks2008}, constructing bisimulations between control flow graphs~\cite{Kundu09}, iteratively applying equality axioms~\cite{Stepp11}, or normalising~\cite{Tristan11} graph representations of the programs.
\emph{Relational Hoare Logic}~\cite{Benton2004,Benton2007,Yang2007,Beringer2011,Barthe2016} (RHL) was proposed by \citeauthor{Benton2004}, in 2004~\cite{Benton2004}, in the course of proving the correctness of various compiler optimisations. The Hoare triple $\{P\} S \{Q\}$ is extended to a Hoare quadruple by inclusion of two statements, rather than one, $\{P\} C_1 \sim C_2 \{Q\}$. The pre and post conditions are lifted to relations over stores. RHL has been extended by various rules to account for differences in structure between the programs~\cite{Benton2004,Barthe2016}. \citeauthor{Barthe2016}~\cite{Barthe2016} pointed out that RHL is closely related to the idea of product programs.
Several formal works tackle the problem of proving program equivalence in the presence of dynamic memory allocation. \citeauthor{Pitts2002} uses a simulation between memory locations when defining a semantic approach to program equivalence~\cite{Pitts2002}, the memory model is flat not a heap. \citeauthor{Benton2007} uses isomorphism between heap regions when proposing an RHL that supports dynamic allocation~\cite{Benton2007}. \citeauthor{Yang2007} constructs a relational separation logic with support for dynamic allocation~\cite{Yang2007}. \citeauthor{Sumner2010} propose a different approach, canonical memory addresses are constructed based on program control flow and syntactic elements. \citeauthor{Banerjee2016}~\cite{Banerjee2016} propose a logic for weaving programs with structural differences so that relational properties of programs can be expressed. They extend this with a region logic to support reasoning about encapsulation in dynamically allocating programs; catering for equivalence between programs which vary the representation of objects.
\subsection{Fully Automatic Equivalence Verification Tools}
To our knowledge there are four other tools with the objective of fully automated verification of procedure equivalence for imperative programs: Symdiff~\cite{Lahiri2012}, RVT~\cite{Godlin09}, SCORE~\cite{Partush2014}, and RÃªve~\cite{Felsing2014}.
Symdiff~\cite{Lahiri2012} uses program verification to prove or provide counter examples of equivalence. It uses mutual summaries, and can infer intermediate summaries to establish equivalence. Conditional equivalence~\cite{Hawblitzel2013} can show partial equivalence over a subset of procedure inputs and construct summaries of interprocedural behavioural differences. Symdiff is built on Boogie~\cite{Barnett2005}. Symdiff has no 
built-in support for procedures that differ in memory allocation.
RVT~\cite{Godlin09} proves equivalence of some C programs. RVT generates loop and recursion free program fragments, which are verified by the CMBC~\cite{Clarke2003} bounded model checker. Loops are encoded as recursive functions. Recursive calls are replaced by uninterpreted functions. Recently support for unbalanced recursive functions has been added~\cite{Strichman2016}. RVT is extended to dynamic data structures involving pointers by generating (symbolic) bounded tree-like data structures as inputs for procedures. These initial tree-like structures are isomorphic up to some bound. RVT then verifies (up to the same bound) that those data structures remain isomorphic, at procedure calls and procedure return. The bound is determined by a syntactic overapproximation of the maximum depth of modification. No rigorous proof is presented for this extension to pointers.
R{\^e}ve~\cite{Felsing2014} and SCORE~\cite{Partush2014} support numerical programs without heaps. R{\^e}ve uses Horn constraints to verify equivalence of deterministic imperative programs with unbounded integer variables. R{\^e}ve infers inductive coupling predicates and as such can deal with loops and recursion where, for example, the number and meaning of procedure parameters has changed. The authors of R{\^e}ve propose in the future to extend their tool with an RVT-like approach to the heap. SCORE uses abstract interpretation over an interleaving of the programs. A good interleaving is found by searching. SCORE deals with numerical programs. For non-equivalent programs SCORE can compute an overapproximation of the semantic difference. The precision of this overapproximation is related to the size of the syntactic difference.
\subsection{Conclusion}\label{sec:conclusion}
We defined procedure equivalence, and a sound methodology \metho{}, for automatically proving equivalence of programs which vary in dynamic memory allocation. We described our \metho{} encoding \tool{} for equivalence verification (available at \url{https://github.com/lexicalscope/ape}). Our approach is fully automatic, and applicable to programs which manipulate heap data structures of any shape.
\printbibliography
%\section*{Appendix}
\end{document}
